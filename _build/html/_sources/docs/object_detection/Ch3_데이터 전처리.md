# 3. ë°ì´í„° ì „ì²˜ë¦¬

2ì¥ì—ì„œëŠ” ë°ì´í„° íƒìƒ‰ì„ í•´ë³´ì•˜ëŠ”ë°, ì´ë²ˆ ì¥ì—ì„œëŠ” ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í•´ë³´ê² ìŠµë‹ˆë‹¤.

ì¸ê¸° ìˆëŠ” ë°ì´í„°ì…‹ì˜ ê²½ìš° ìˆ˜ì²œ ìˆ˜ë§Œì¥ì˜ ì´ë¯¸ì§€ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ëª¨ë“  ë°ì´í„°ì…‹ì´ ê·¸ë ‡ì§„ ëª»í•©ë‹ˆë‹¤.  ê·¸ëŸ¬ë©´ ì œí•œëœ ë°ì´í„°ì…‹ì„ í•™ìŠµ ì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ì–´ë–»ê²Œ í•´ê²° í•´ì•¼ í• ê¹Œìš”?

ìš°ë¦¬ëŠ” ë°ì´í„°ì…‹ì´ ë¶€ì¡±í•˜ë‹¤ê³  ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ì™œëƒí•˜ë©´ ë°ì´í„° Augmentationì„ ì´ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ìƒíƒœì˜ ì´ë¯¸ì§€ë¥¼ ì–»ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. 

![](https://drive.google.com/uc?id=1ammM-EnG9aCvMsLvpm-P-6UvOz56M9P3)
- ê·¸ë¦¼ 3.1 ê°™ì•„ ë³´ì´ì§€ë§Œ ë‹¤ë¥¸ í…Œë‹ˆìŠ¤ ê³µ (ì¶œì²˜:https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/)

ê·¸ë¦¼ 3.1ì€ ì‚¬ëŒì´ ë³´ê¸°ì—” ë‹¤ ë˜‘ê°™ì€ í…Œë‹ˆìŠ¤ ê³µì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì‹ ê²½ë§ì€ 3ê°œì˜ í…Œë‹ˆìŠ¤ ê³µì„ ë‹¤ ë‹¤ë¥´ê²Œ ë´…ë‹ˆë‹¤. ì´ì™€ ê°™ì€ ì›ë¦¬ë¡œ ìš°ë¦¬ëŠ” í•˜ë‚˜ì˜ ì‚¬ì§„ì„ ë³€ì¡° ì‹œì¼œ ì—¬ëŸ¬ ê°œì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

3.1ì ˆì—ì„œëŠ” ì´ë¯¸ì§€ Augmentationì´ ì‚¬ìš©ë˜ëŠ” torchvision.transformsì™€ Albumentations ëª¨ë“ˆì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. torchvision.transformsëŠ” íŒŒì´í† ì¹˜ì—ì„œ ê³µì‹ì ìœ¼ë¡œ ì œê³µí•˜ëŠ” ëª¨ë“ˆì´ë©° AlbumentationsëŠ” OpenCVì™€ ê°™ì€ ì˜¤í”ˆ ì†ŒìŠ¤ ì»´í“¨í„° ë¹„ì ¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ìµœì í™” í•˜ì˜€ê¸°ì— ë‹¤ë¥¸ image argumentation ë¼ì´ë¸ŒëŸ¬ë¦¬ë³´ë‹¤ ë” ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ ë° ê¸°íƒ€ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤. 

ì–¸ê¸‰ëœ ë‘ ëª¨ë“ˆ ëª¨ë‘ ì´ë¯¸ì§€ ë¶„ë¥˜ìš© ëª¨ë¸ êµ¬ì¶•ì„ ìœ„í•œ augmentationì—ëŠ” ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ê°ì²´ íƒì§€ìš© ëª¨ë¸ êµ¬ì¶•ì„ ìœ„í•œ ì´ë¯¸ì§€ augmentation ê¸°ëŠ¥ì€ Albumentationsì—ì„œë§Œ ì œê³µ ë©ë‹ˆë‹¤. ê°ì²´ íƒì§€ìš© ì´ë¯¸ì§€ Augmentationì€ ì´ë¯¸ì§€ ë¿ë§Œ ì•„ë‹ˆë¼ ë°”ìš´ë”© ë°•ìŠ¤ ê¹Œì§€ ë³€í˜•ì„ ì£¼ì–´ì•¼ í•˜ëŠ”ë°, torchvision.transformsì—ëŠ” í•´ë‹¹ ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 

ê·¸ëŸ¬ë¯€ë¡œ 3.2ì ˆì—ì„œëŠ” Albumentationsë¥¼ í™œìš©í•´ ë°”ìš´ë”© ë°•ìŠ¤ augmentationì„ ì‹¤ìŠµí•´ë³´ê² ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ 3.3ì ˆì—ì„œëŠ” ë°ì´í„°ë¥¼ í›ˆë ¨ìš© ë°ì´í„°ì™€ ì‹œí—˜ìš© ë°ì´í„°ë¡œ ë¶„ë¦¬í•˜ëŠ” ì‘ì—…ì„ ì‹¤ì‹œí•˜ê² ìŠµë‹ˆë‹¤.



## 3.1 Augmentation ì‹¤ìŠµ

Augmentation ì‹¤ìŠµì„ ìœ„í•´ 2.1ì ˆì— ë‚˜ì˜¨ ì½”ë“œë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê² ìŠµë‹ˆë‹¤.


```python
!git clone https://github.com/Pseudo-Lab/Tutorial-Book-DataLoader
!python Tutorial-Book-DataLoader/PL_data_loader.py --data FaceMaskDetection
!unzip -q Face\ Mask\ Detection.zip
```

    Cloning into 'Tutorial-Book-DataLoader'...
    remote: Enumerating objects: 6, done.[K
    remote: Counting objects: 100% (6/6), done.[K
    remote: Compressing objects: 100% (5/5), done.[K
    remote: Total 6 (delta 0), reused 3 (delta 0), pack-reused 0[K
    Unpacking objects: 100% (6/6), done.
    Face Mask Detection.zip is done!
    

ìµœì‹  ë²„ì „ì˜ albumentations ëª¨ë“ˆì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì—…ê·¸ë ˆì´ë“œë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.


```python
!pip install --upgrade albumentations
```

    Collecting albumentations
    [?25l  Downloading https://files.pythonhosted.org/packages/95/b2/9492c74a5d260bc39f0cba9fcdc6652d0f87d342aaeb32197c62029f82df/albumentations-0.5.1-py3-none-any.whl (71kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 5.2MB/s eta 0:00:011
    [?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (3.13)
    Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)
    Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.18.5)
    Requirement already satisfied, skipping upgrade: scikit-image>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (0.16.2)
    Collecting imgaug>=0.4.0
    [?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 952kB 13.6MB/s 
    [?25hCollecting opencv-python-headless>=4.1.1
    [?25l  Downloading https://files.pythonhosted.org/packages/08/e9/57d869561389884136be65a2d1bc038fe50171e2ba348fda269a4aab8032/opencv_python_headless-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (36.7MB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36.7MB 128kB/s 
    [?25hRequirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)
    Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (7.0.0)
    Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5)
    Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)
    Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)
    Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)
    Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (4.1.2.30)
    Requirement already satisfied, skipping upgrade: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)
    Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)
    Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)
    Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)
    Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)
    Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)
    Installing collected packages: imgaug, opencv-python-headless, albumentations
      Found existing installation: imgaug 0.2.9
        Uninstalling imgaug-0.2.9:
          Successfully uninstalled imgaug-0.2.9
      Found existing installation: albumentations 0.1.12
        Uninstalling albumentations-0.1.12:
          Successfully uninstalled albumentations-0.1.12
    Successfully installed albumentations-0.5.1 imgaug-0.4.0 opencv-python-headless-4.4.0.46
    

augmentation ê²°ê³¼ë¬¼ì„ ì‹œê°í™”í•˜ê¸° ìœ„í•´ 2.3ì ˆì— ë‚˜ì˜¨ ë°”ìš´ë”© ë°•ìŠ¤ ë„ì‹í™” ì½”ë“œë¥¼ ê°€ì§€ê³  ì˜¤ê² ìŠµë‹ˆë‹¤.


```python
import os
import glob
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.patches as patches
from bs4 import BeautifulSoup

def generate_box(obj):
    xmin = float(obj.find('xmin').text)
    ymin = float(obj.find('ymin').text)
    xmax = float(obj.find('xmax').text)
    ymax = float(obj.find('ymax').text)
    
    return [xmin, ymin, xmax, ymax]

def generate_label(obj):
    if obj.find('name').text == "with_mask":
        return 1
    elif obj.find('name').text == "mask_weared_incorrect":
        return 2

    return 0

def generate_target(file): 
    with open(file) as f:
        data = f.read()
        soup = BeautifulSoup(data, "html.parser")
        objects = soup.find_all("object")

        num_objs = len(objects)

        boxes = []
        labels = []
        for i in objects:
            boxes.append(generate_box(i))
            labels.append(generate_label(i))

        boxes = torch.as_tensor(boxes, dtype=torch.float32)
        labels = torch.as_tensor(labels, dtype=torch.int64)
        
        target = {}
        target["boxes"] = boxes
        target["labels"] = labels
        
        return target

def plot_image_from_output(img_path, annotation):
    
    img = img_path.cpu().permute(1,2,0)
    
    fig,ax = plt.subplots(1)
    ax.imshow(img)
    
    for idx in range(len(annotation["boxes"])):
        xmin, ymin, xmax, ymax = annotation["boxes"][idx]

        if annotation['labels'][idx] == 0 :
            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='r',facecolor='none')
        
        elif annotation['labels'][idx] == 1 :
            
            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='g',facecolor='none')
            
        else :
        
            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='b',facecolor='none')

        ax.add_patch(rect)

    plt.show()
```

### 3.1.1 Torchvision Transforms

torchvision.transformsì„ ì‹¤ìŠµí•˜ê¸° ìœ„í•´ `TorchvisionDataset` í´ë˜ìŠ¤ë¥¼ ë¨¼ì € ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤. `TorchvisionDataset` í´ë˜ìŠ¤ëŠ”`__getitem__` ë©”ì†Œë“œë¥¼ í†µí•´ imageë¥¼ ë¶ˆëŸ¬ì˜¨ ë‹¤ìŒ ë°ì´í„° augmentationì„ ì§„í–‰í•©ë‹ˆë‹¤. transform íŒŒë¼ë¯¸í„°ì— ì €ì¥ë¼ ìˆëŠ” augmenation ê·œì¹™ì— ì˜í•´ augmentationì´ ì´ë¤„ì§‘ë‹ˆë‹¤. ì‹œê°„ ì¸¡ì •ì„ ìœ„í•´ `time`í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê° ì¸¡ì • í›„, ìµœì¢…ì ìœ¼ë¡œ image, label, total_timeì„ ë°˜í™˜í•´ì¤ë‹ˆë‹¤.


```python
from PIL import Image
import cv2
import numpy as np
import time
import torch
import torchvision
from torch.utils.data import Dataset
from torchvision import transforms
import albumentations
import albumentations.pytorch
from matplotlib import pyplot as plt
import os
from PIL import Image
import random

class TorchvisionMaskDataset(Dataset):
    def __init__(self, path, transform=None):
        self.path = path
        self.imgs = list(sorted(os.listdir(self.path)))
        self.transform = transform
        
    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        file_image = self.imgs[idx]
        file_label = self.imgs[idx][:-3] + 'xml'
        img_path = os.path.join(self.path, file_image)
        
        if 'test' in self.path:
            label_path = os.path.join("test_annotations/", file_label)
        else:
            label_path = os.path.join("annotations/", file_label)

        img = Image.open(img_path).convert("RGB")
        #Generate Label
        target = generate_target(label_path)
        
        start_t = time.time()
        if self.transform:
            img = self.transform(img)

        total_time = (time.time() - start_t)

        return img, target, total_time
```

trainsformsì—ì„œ ì œê³µí•˜ëŠ” í•¨ìˆ˜ë¥¼ í™œìš©í•´ ì´ë¯¸ì§€ augmentation ì‹¤ìŠµì„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ (300, 300) í¬ê¸°ë¡œ ë§Œë“  í›„, ì´ë¯¸ì§€ë¥¼ 224 í¬ê¸°ë¡œ ìë¥´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‚˜ì„œ ì´ë¯¸ì§€ì˜ ë°ê¸°(brightness), ëŒ€ë¹„(contrast), ì±„ë„(saturation), ìƒ‰ì¡°(hue)ë¥¼ ë¬´ì‘ìœ„ë¡œ ë°”ê¿”ë³´ê² ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì¢Œìš°ë°˜ì „ì„ ì ìš©ì‹œí‚¨ í›„ ToTensorë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤.


```python
torchvision_transform = transforms.Compose([
    transforms.Resize((300, 300)), 
    transforms.RandomCrop(224),
    transforms.ColorJitter(0.2,0.2,0.2,0.2),
    transforms.RandomHorizontalFlip(p = 1),
    transforms.ToTensor(),
])

torchvision_dataset = TorchvisionMaskDataset(
    path = 'images/',
    transform = torchvision_transform
)
```

transformsì—ì„œ ì œê³µí•˜ëŠ” `Resize` í•¨ìˆ˜ë¥¼ í†µí•´ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìœ¼ë©°, `RandomCrop` í•¨ìˆ˜ë¥¼ í†µí•´ í¬ê¸°ë¥¼ ìë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. `ColorJitter` í•¨ìˆ˜ëŠ” ë°ê¸°, ëŒ€ë¹„, ì±„ë„, ìƒ‰ì¡° ë“±ì„ ì„ì˜ë¡œ ë°”ê¾¸ëŠ” ê¸°ëŠ¥ì„ í•˜ë©° `RandomHorizontalFlip`ì€ ì •ì˜í•œ pì˜ í™•ë¥ ë¡œ ì¢Œìš°ë°˜ì „ì„ ì‹¤ì‹œí•©ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•´ ë³€ê²½ ì „ê³¼ ë³€ê²½ í›„ì˜ ì´ë¯¸ì§€ë¥¼ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤.


```python
# ë³€ê²½ ì „
torchvision_dataset_no_transform = TorchvisionMaskDataset(
    path = 'images/'
)
img, annot, transform_time = torchvision_dataset_no_transform[0]
plot_image_from_output(torch.as_tensor(np.array(img)).permute(2,0,1), annot)
```


![png](output_12_0.png)



```python
# ë³€ê²½ í›„
img, annot, transform_time = torchvision_dataset[0]
plot_image_from_output(img, annot)
```


![png](output_13_0.png)


ë³€ê²½ ì „ì— ë¹„í•´ ë³€ê²½ í›„ ì´ë¯¸ì§€ëŠ” ì•ì„œ ì–¸ê¸‰í•œ ë³€í™”ë“¤ì´ ì ìš©ëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ë¯¸ì§€ ìì²´ì ì¸ ë³€í™”ëŠ” ì´ë¤„ì¡Œì§€ë§Œ ë°”ìš´ë”© ë°•ìŠ¤ëŠ” ë³€í™”ëœ ì´ë¯¸ì§€ì—ì„œ ìœ„ì¹˜ê°€ ì–´ê¸‹ ë‚œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. torchvision.transformì—ì„œ ì œê³µí•˜ëŠ” augmentationì€ ì´ë¯¸ì§€ ê°’ì— ëŒ€í•œ augmentationë§Œ ì§„í–‰ì´ ë˜ë©°, ê·¸ì— ë”°ë¼ ë°”ìš´ë”© ë°•ìŠ¤ëŠ” ê°™ì´ ë³€í™˜ ë˜ì§€ ì•ŠëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì—ì„œëŠ” ì´ë¯¸ì§€ê°€ ë³€í•´ë„ ë¼ë²¨ ê°’ì´ ê³ ì •ì´ì§€ë§Œ, ê°ì²´ ê²€ì¶œ ë¬¸ì œì—ì„œëŠ” ì´ë¯¸ì§€ê°€ ë³€í•¨ì— ë”°ë¼ ë¼ë²¨ ê°’ ë˜í•œ í•¨ê»˜ ë³€í•´ì•¼ í•©ë‹ˆë‹¤. 3.2 ì ˆì—ì„œ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ìš°ì„  3.1 ì ˆì—ì„œëŠ” torchvisionê³¼ albumentations ëª¨ë“ˆ ë¹„êµë¥¼ ê³„ì† ì§„í–‰í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. torchvision_datasetì—ì„œ ì´ë¯¸ì§€ ë³€í™˜ì— ì†Œìš”ëœ ì‹œê°„ì„ ê³„ì‚°í•˜ê³  ê·¸ê²ƒì„ 100ë²ˆ ë°˜ë³µí•œ ì‹œê°„ì„ ì•„ë˜ ì½”ë“œë¥¼ í™œìš©í•´ ì¸¡ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
total_time = 0
for i in range(100):
  sample, _, transform_time = torchvision_dataset[0]
  total_time += transform_time

print("torchvision time: {} ms".format(total_time*10))
```

    torchvision time: 11.102776527404785 ms
    

ì´ë¯¸ì§€ ë³€í™˜ì„ 100ë²ˆ ìˆ˜í–‰í•˜ëŠ”ë° ì•½ 11.2 msê°€ ì†Œìš”ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 3.1.2 Albumentation

ì•ì„œ 3.1.1ì ˆì—ì„œëŠ” torchvision.transformsì˜ ë³€í™˜ ì†ë„ë¥¼ ì¸¡ì •í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ë²ˆ ì ˆì—ì„œëŠ” ë˜ ë‹¤ë¥¸ augmentation ëª¨ë“ˆì¸ Albumentationsë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. torchvisionê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ë¨¼ì € ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤. `AlbumentationDataset`ì€ `TorchVisionDataset`ê³¼ ë¹„ìŠ·í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
cv2 ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì½ê³  RGBë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ë¯¸ì§€ ë³€í™˜ì„ ì‹¤ì‹œí•œ í›„ ê²°ê³¼ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤ 


```python
class AlbumentationsDataset(Dataset):
    def __init__(self, path, transform=None):
        self.path = path
        self.imgs = list(sorted(os.listdir(self.path)))
        self.transform = transform
        
    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        file_image = self.imgs[idx]
        file_label = self.imgs[idx][:-3] + 'xml'
        img_path = os.path.join(self.path, file_image)

        if 'test' in self.path:
            label_path = os.path.join("test_annotations/", file_label)
        else:
            label_path = os.path.join("annotations/", file_label)
        
        # Read an image with OpenCV
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        target = generate_target(label_path)

        start_t = time.time()
        if self.transform:
            augmented = self.transform(image=image)
            total_time = (time.time() - start_t)
            image = augmented['image']
        
            
        return image, target, total_time
```

torchvision.transformê³¼ì˜ ì†ë„ ë¹„êµë¥¼ ìœ„í•´ ê°™ì€ ê¸°ëŠ¥ì¸ `Resize`, `RandomCrop`, `ColorJitter`, `HorizontalFlip`ì„ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‚˜ì„œ ë³€ê²½ ì „ê³¼ ë³€ê²½ í›„ ì´ë¯¸ì§€ë¥¼ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤.


```python
# Same transform with torchvision_transform
albumentations_transform = albumentations.Compose([
    albumentations.Resize(300, 300), 
    albumentations.RandomCrop(224, 224),
    albumentations.ColorJitter(p=1), 
    albumentations.HorizontalFlip(p=1), 
    albumentations.pytorch.transforms.ToTensor()
])
```


```python
# ë³€ê²½ ì „
img, annot, transform_time = torchvision_dataset_no_transform[0]
plot_image_from_output(torch.as_tensor(np.array(img)).permute(2,0,1), annot)
```


![png](output_21_0.png)



```python
# ë³€ê²½ í›„
albumentation_dataset = AlbumentationsDataset(
    path = 'images/',
    transform = albumentations_transform
)

img, annot, transform_time = albumentation_dataset[0]
plot_image_from_output(img, annot)
```


![png](output_22_0.png)


torchvisionê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì´ë¯¸ì§€ ë³€í™˜ì´ ì´ë£¨ì–´ ì¡Œì§€ë§Œ, ë°”ìš´ë”© ë°•ìŠ¤ëŠ” ë³€í•˜ì§€ ì•Šì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì†ë„ ì¸¡ì •ì„ ìœ„í•´ transformì„ 100ë²ˆ ì ìš© ì‹œí‚¨ ë’¤ ì‹œê°„ì„ ì¸¡ì •í•˜ê² ìŠµë‹ˆë‹¤



```python
total_time = 0
for i in range(100):
    sample, _, transform_time = albumentation_dataset[0]
    total_time += transform_time

print("albumentations time/sample: {} ms".format(total_time*10))
```

    albumentations time/sample: 2.4160075187683105 ms
    

ì´ë¯¸ì§€ ë³€í™˜ì„ 100ë²ˆ ìˆ˜í–‰í•˜ëŠ”ë° ì•½ 2.4 msê°€ ì†Œìš”ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. torchvision.transformsì™€ ë¹„êµí–ˆì„ ë•Œ ì•½ 4ë°° ì •ë„ ë¹ ë¥¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

### 3.1.3 í™•ë¥  ê¸°ë°˜ Augmentation ì¡°í•©


AlbmentationsëŠ” torchvision.transforms ë³´ë‹¤ ì†ë„ê°€ ë¹ ë¥¼ ë¿ë§Œ ì•„ë‹ˆë¼ ìƒˆë¡œìš´ ê¸°ëŠ¥ ë˜í•œ ì œê³µí•©ë‹ˆë‹¤. ì´ë²ˆ ì ˆì—ì„œëŠ” Albumentationsì—ì„œ ì œê³µí•˜ëŠ” `OneOf` í•¨ìˆ˜ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” list ì•ˆì— ìˆëŠ” augmentation ê¸°ëŠ¥ ë“¤ì„ ì£¼ì–´ì§„ í™•ë¥  ê°’ì— ê¸°ë°˜í•˜ì—¬ ê°€ì ¸ì˜µë‹ˆë‹¤. list ê°’ ìì²´ì˜ í™•ë¥  ê°’ê³¼ ë”ë¶ˆì–´ í•´ë‹¹ í•¨ìˆ˜ì˜ í™•ë¥  ê°’ì„ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ ì‹¤í–‰ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ì•„ë˜ì˜ `OneOf` í•¨ìˆ˜ëŠ” ê°ê° ì„ íƒë  í™•ë¥ ì´ 1 ì…ë‹ˆë‹¤. ê°ê°ì˜ í•¨ìˆ˜ ë‚´ë¶€ì— ìˆëŠ” 3ê°œì˜ albumentations ê¸°ëŠ¥ë“¤ ë˜í•œ ê°ê° í™•ë¥  ê°’ì´ 1ë¡œ ë¶€ì—¬ ë¬ìœ¼ë¯€ë¡œ, ì‹¤ì§ˆì ìœ¼ë¡œ 1/3ì˜ í™•ë¥ ë¡œ 3ê°œì˜ ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ê°€ ì„ íƒë˜ì–´ ì‹¤í–‰ ëœë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í™•ë¥  ê°’ì„ ì¡°ì •í•˜ì—¬ ë‹¤ì–‘í•œ augmentationì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. 


```python
albumentations_transform_oneof = albumentations.Compose([
    albumentations.Resize(300, 300), 
    albumentations.RandomCrop(224, 224),
    albumentations.OneOf([
                          albumentations.HorizontalFlip(p=1),
                          albumentations.RandomRotate90(p=1),
                          albumentations.VerticalFlip(p=1)            
    ], p=1),
    albumentations.OneOf([
                          albumentations.MotionBlur(p=1),
                          albumentations.OpticalDistortion(p=1),
                          albumentations.GaussNoise(p=1)                 
    ], p=1),
    albumentations.pytorch.ToTensor()
])
```

ì•„ë˜ëŠ” albumentations_transform_oneofë¥¼ ì´ë¯¸ì§€ì— 10ë²ˆ ì ìš©í•œ ê²°ê³¼ì…ë‹ˆë‹¤. 


```python
albumentation_dataset_oneof = AlbumentationsDataset(
    path = 'images/',
    transform = albumentations_transform_oneof
)

num_samples = 10
fig, ax = plt.subplots(1, num_samples, figsize=(25, 5))
for i in range(num_samples):
  ax[i].imshow(transforms.ToPILImage()(albumentation_dataset_oneof[0][0]))
  ax[i].axis('off')
```


![png](output_29_0.png)


## 3.2 ë°”ìš´ë”© ë°•ìŠ¤ Augmentation

ê°ì²´ íƒì§€ ëª¨ë¸ êµ¬ì¶•ì— ì‚¬ìš©ë˜ëŠ” ì´ë¯¸ì§€ì— ëŒ€í•œ augmentation ì§„í–‰ ì‹œ, ì´ë¯¸ì§€ ë³€í™˜ ë¿ë§Œ ì•„ë‹ˆë¼ ê·¸ì— ë”°ë¥¸ ë°”ìš´ë”© ë°•ìŠ¤ ë³€í™˜ ë˜í•œ í•¨ê»˜ ì§„í–‰í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. 3.1ì ˆì—ì„œ ë³´ì•˜ë“¯ì´ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ í•¨ê»˜ ë³€í™˜ ì‹œì¼œ ì£¼ì§€ ì•Šìœ¼ë©´ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì—‰ëš±í•œ ê³³ì„ íƒì§€í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ëª¨ë¸ í•™ìŠµì´ ì œëŒ€ë¡œ ì´ë¤„ì§€ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤. Albumentationsì—ì„œ ì œê³µí•˜ëŠ” Compose í•¨ìˆ˜ì— ìˆëŠ” bbox_params íŒŒë¼ë¯¸í„°ë¥¼ í™œìš©í•˜ë©´ ë°”ìš´ë”© ë°•ìŠ¤ augmentationì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ìš°ì„  ì•„ë˜ ì½”ë“œë¥¼ í™œìš©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤. 3.1.2 ì ˆì—ì„œ í™•ì¸í•œ `AlbumentationsDataset` í´ë˜ìŠ¤ì˜ transform ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ë¿ë§Œ ì•„ë‹ˆë¼ ë°”ìš´ë”© ë°•ìŠ¤ë„ transformì´ ì§„í–‰ë˜ê¸° ë•Œë¬¸ì— í•„ìš”í•œ ì…ë ¥ê°’, ì¶œë ¥ê°’ ìˆ˜ì •ì„ ì§„í–‰í•´ì£¼ì—ˆìŠµë‹ˆë‹¤. 


```python
class BboxAugmentationDataset(Dataset):
    def __init__(self, path, transform=None):
        self.path = path
        self.imgs = list(sorted(os.listdir(self.path)))
        self.transform = transform
        
    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        file_image = self.imgs[idx]
        file_label = self.imgs[idx][:-3] + 'xml'
        img_path = os.path.join(self.path, file_image)

        if 'test' in self.path:
            label_path = os.path.join("test_annotations/", file_label)
        else:
            label_path = os.path.join("annotations/", file_label)
        
        # Read an image with OpenCV
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        target = generate_target(label_path)

        start_t = time.time()
        if self.transform:
            transformed = self.transform(image = image, bboxes = target['boxes'], labels = target['labels'])
            total_time = (time.time() - start_t)
            image = transformed['image']
            target = {'boxes':transformed['bboxes'], 'labels':transformed['labels']}
        
            
        return image, target, total_time
```

ë‹¤ìŒìœ¼ë¡œëŠ” `albumentations.Compose` í•¨ìˆ˜ë¥¼ í™œìš©í•´ ë³€í™˜ì„ ì •ì˜í•´ë³´ê² ìŠµë‹ˆë‹¤. ê°€ì¥ ë¨¼ì € ì¢Œìš°ë°˜ì „ì„ ì‹¤ì‹œí•  ê²ƒì´ë©°, ê·¸ ì´í›„ì— -90ë„ì—ì„œ 90ë„ ì‚¬ì´ì˜ íšŒì „ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ë°”ìš´ë”© ë°•ìŠ¤ë„ í•¨ê»˜ ë³€í™˜ì„ ì§„í–‰í•´ì£¼ê¸° ìœ„í•´ bbox_params íŒŒë¼ë¯¸í„°ì— `albumentations.BboxParams` ê°ì²´ë¥¼ ì…ë ¥í•´ì¤ë‹ˆë‹¤. Face Mask Detection ë°ì´í„°ì…‹ì€ ë°”ìš´ë”© ë°•ìŠ¤ í‘œê¸°ë²•ì´ `xmin`, `ymin`, `xmax`, `ymax`ìœ¼ë¡œ ë¼ìˆê³ , ì´ê²ƒì€ pascal_voc í‘œê¸°ë²•ê³¼ ê°™ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ format íŒŒë¼ë¯¸í„°ì— pascal_vocì„ ì…ë ¥í•©ë‹ˆë‹¤. ë˜í•œ `transform` ì§„í–‰ ì‹œ ê°ì²´ ë³„ í´ë˜ìŠ¤ ê°’ì€ `labels` íŒŒë¼ë¯¸í„°ì— ì €ì¥í•´ë‘ê¸° ìœ„í•´ `label_field`ì— `labels`ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.


```python
bbox_transform = albumentations.Compose(
    [albumentations.HorizontalFlip(p=1),
     albumentations.Rotate(p=1),
     albumentations.pytorch.transforms.ToTensor()],
    bbox_params=albumentations.BboxParams(format='pascal_voc', label_fields=['labels']),
)
```

ì´ì œ `BboxAugmentationDataset` í´ë˜ìŠ¤ë¥¼ í™œì„±í™” í•˜ì—¬ augmentation ê²°ê³¼ë¬¼ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


```python
bbox_transform_dataset = BboxAugmentationDataset(
    path = 'images/',
    transform = bbox_transform
)

img, annot, transform_time = bbox_transform_dataset[0]
plot_image_from_output(img, annot)
```


![png](output_35_0.png)


ìœ„ ì½”ë“œë¥¼ ì‹¤í–‰í•  ë•Œ ë§ˆë‹¤ ì´ë¯¸ì§€ê°€ ë³€í™˜ë˜ì–´ì„œ ì¶œë ¥ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ì™€ ë”ë¶ˆì–´ ë°”ìš´ë”© ë°•ìŠ¤ ë˜í•œ ì•Œë§ê²Œ ë³€í™˜ë˜ì–´ ë³€í™˜ëœ ì´ë¯¸ì§€ì— ìˆëŠ” ë§ˆìŠ¤í¬ ì°©ìš© ì–¼êµ´ë“¤ì„ ì •í™•íˆ íƒì§€í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ì´ë¯¸ì§€ì™€ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ í•¨ê»˜ ë³€í™˜í•œ ë°ì´í„°ë¥¼ í™œìš©í•´ 4ì¥ê³¼ 5ì¥ì—ì„œ ëª¨ë¸ì„ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤. 

## 3.3 ë°ì´í„° ë¶„ë¦¬ 

ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ì„  í•™ìŠµìš© ë°ì´í„°ì™€ ì‹œí—˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. í•™ìŠµìš© ë°ì´í„°ëŠ” ëª¨ë¸ í›ˆë ¨ ì‹œ ì‚¬ìš©í•˜ë©° ì‹œí—˜ ë°ì´í„°ëŠ” ëª¨ë¸ í‰ê°€ ì‹œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‹œí—˜ ë°ì´í„°ëŠ” í•™ìŠµìš© ë°ì´í„°ì™€ ì¤‘ë³µ ë˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤. 3.1ì ˆì—ì„œ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ë¥¼ í•™ìŠµ ë°ì´í„°ì™€ ì‹œí—˜ ë°ì´í„°ë¡œ ë‚˜ëˆ„ì–´ ë³´ê² ìŠµë‹ˆë‹¤. 

ìš°ì„  ì „ì²´ ë°ì´í„°ì˜ ê°œìˆ˜ë¥¼ ì•„ë˜ ì½”ë“œë¥¼ í†µí•´ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. 


```python
print(len(os.listdir('annotations')))
print(len(os.listdir('images')))
```

    853
    853
    

ì´ 853ê°œì˜ ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ í•™ìŠµ ë°ì´í„°ì™€ ì‹œí—˜ ë°ì´í„°ì˜ ë¹„ìœ¨ì€ 7:3 ìœ¼ë¡œ ê°€ì ¸ê°‘ë‹ˆë‹¤. ì´ë²ˆ ë°ì´í„°ëŠ” ì „ì²´ ë°ì´í„°ì…‹ ê°œìˆ˜ê°€ ì ìœ¼ë¯€ë¡œ 8:2 ë¹„ìœ¨ì„ ê°€ì ¸ê°€ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. 853ê°œì˜ ë°ì´í„° ì¤‘ 170ê°œë¥¼ ì‹œí—˜ ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í•´ë‹¹ ë°ì´í„°ë¥¼ ë³„ë„ì˜ í´ë”ë¡œ ì˜®ê²¨ ì£¼ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ìš°ì„  ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´ mkdirë¥¼ í™œìš©í•˜ì—¬ ì‹œí—˜ ë°ì´í„°ë¥¼ ë‹´ì„ í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 


```python
!mkdir test_images
!mkdir test_annotations
```

ìœ„ ì½”ë“œë¥¼ ì‹¤í–‰ í•˜ë©´ test_images í´ë”ì™€ test_annotations í´ë”ê°€ ìƒì„±ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì œ images í´ë”ì™€ annotations í´ë”ì— ìˆëŠ” íŒŒì¼ ê°ê° 170ê°œì”©ì„ ìƒˆë¡œ ìƒì„±í•œ í´ë”ë¡œ ì˜®ê¸°ê² ìŠµë‹ˆë‹¤. random ëª¨ë“ˆì— ìˆëŠ” sample í•¨ìˆ˜ë¥¼ í™œìš©í•´ ë¬´ì‘ìœ„ë¡œ ìˆ«ìë¥¼ ì¶”ì¶œí•œ í›„ ì¸ë±ìŠ¤ ê°’ìœ¼ë¡œ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤. 


```python
import random
random.seed(1234)
idx = random.sample(range(853), 170)
print(len(idx))
print(idx[:10])
```

    170
    [796, 451, 119, 7, 92, 826, 596, 35, 687, 709]
    


```python
import numpy as np
import shutil

for img in np.array(sorted(os.listdir('images')))[idx]:
    shutil.move('images/'+img, 'test_images/'+img)

for annot in np.array(sorted(os.listdir('annotations')))[idx]:
    shutil.move('annotations/'+annot, 'test_annotations/'+annot)


```

ìœ„ì˜ ì½”ë“œ ì²˜ëŸ¼ shutil íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•´ 170ê°œì˜ ì´ë¯¸ì§€ì™€ 170ê°œì˜ ì¢Œí‘œ íŒŒì¼ë“¤ì„ ê°ê° test_imagesí´ë”ì™€ test_annotations í´ë”ë¡œ ì˜®ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° í´ë”ë³„ íŒŒì¼ ê°œìˆ˜ë¥¼ í™•ì¸í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ë‚˜ì˜¬ ê²ƒì…ë‹ˆë‹¤. 


```python
print(len(os.listdir('annotations')))
print(len(os.listdir('images')))
print(len(os.listdir('test_annotations')))
print(len(os.listdir('test_images')))
```

    683
    683
    170
    170
    

ì§€ê¸ˆê¹Œì§€ Albumentations ëª¨ë“ˆì„ í™œìš©í•´ ê°ì²´ ê²€ì¶œ ëª¨ë¸ êµ¬ì¶•ì— ì‚¬ìš©ë˜ëŠ” ì´ë¯¸ì§€ë¥¼ ë¶€í’€ë¦¬ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì•˜ê³ , ë³´ìœ í•œ ë°ì´í„°ë¥¼ í•™ìŠµìš© ë°ì´í„°ì™€ ì‹œí—˜ìš© ë°ì´í„°ë¡œ ë¶„ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. 4ì¥ì—ì„œëŠ” One-Stage ëª¨ë¸ì¸ RetinaNetì„ í•™ìŠµì‹œì¼œ ë§ˆìŠ¤í¬ ì°©ìš© íƒì§€ ëª¨ë¸ì„ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤. 

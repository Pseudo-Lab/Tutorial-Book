
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. 객체 탐지(Object Detection) &#8212; PseudoLab Tutorial Book</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "Pseudo-Lab/Tutorial-Book");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../../_static/PseudoLab_logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2. 데이터 탐색" href="Ch2%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%ED%83%90%EC%83%89.html" />
    <link rel="prev" title="파이토치를 활용한 딥러닝 튜토리얼 (Deep Learning Tutorials using PyTorch)" href="../index.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/PseudoLab_logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">PseudoLab Tutorial Book</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   파이토치를 활용한 딥러닝 튜토리얼 (Deep Learning Tutorials using PyTorch)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  객체 탐지(Object Detection)
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. 객체 탐지(Object Detection)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ch2%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%ED%83%90%EC%83%89.html">
   2. 데이터 탐색
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ch3%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%A0%84%EC%B2%98%EB%A6%AC.html">
   3. 데이터 전처리
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ch4%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%AA%A8%EB%8D%B8%EB%A7%81.html">
   4. 데이터 모델링
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ch5%20%EC%84%B1%EB%8A%A5%20%ED%96%A5%EC%83%81%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%B0%A9%EB%B2%95.html">
   5. 성능 향상을 위한 방법
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/docs/object_detection/Ch1 Object Detection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Pseudo-Lab/Tutorial-Book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/Pseudo-Lab/Tutorial-Book/issues/new?title=Issue%20on%20page%20%2Fdocs/object_detection/Ch1 Object Detection.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/Pseudo-Lab/Tutorial-Book/master?urlpath=tree/mini_book/docs/object_detection/Ch1 Object Detection.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   1.1. 바운딩 박스
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   1.2. 모델 형태
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-stage-detector">
     1.2.1. One-Stage Detector
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-stage-detector">
     1.2.2. Two-Stage Detector
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   1.3. 모델 구조
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-cnn">
     1.3.1. R-CNN
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fast-r-cnn">
     1.3.2. Fast R-CNN
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#faster-r-cnn">
     1.3.3. Faster R-CNN
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#yolo">
     1.3.4. YOLO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ssd">
     1.3.5. SSD
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#retinanet">
     1.3.6. RetinaNet
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="object-detection">
<h1>1. 객체 탐지(Object Detection)<a class="headerlink" href="#object-detection" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://colab.research.google.com/drive/1iKVsHy8y9ctIpv34gsyilpvwC0fBm85H?usp=sharing"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p>객체 탐지(Object Detection)는 컴퓨터 비전 기술의 세부 분야중 하나로써 주어진 이미지내 사용자가 관심 있는 객체를 탐지하는 기술입니다.</p>
<p>인공지능 모델이 그림 1.1 좌측에 있는 강아지 사진을  강아지라고 판별한다면 해당 모델은 이미지 분류 모델 입니다. 하지만 우측 사진 처럼 물체가 있는 위치를 탐지함과 동시에 해당 물체가 강아지라고 분류 한다면 해당 모델은 객체 탐지 모델입니다.</p>
<p><img alt="" src="https://drive.google.com/uc?id=1qFN7jJpM-VsR7SIMvbxDO4fGrvqCZvrz" /></p>
<ul class="simple">
<li><p>그림 1.1 이미지 분류 모델과 객체 탐지 모델 비교 (출처: https://www.pexels.com/search/dog/)</p></li>
</ul>
<p>객체 탐지 모델은 여러 분야에서 활용 가능합니다. 가장 대표적인 활용 사례는 자율 주행 자동차입니다. 자율 주행 자동차를 만들기 위해서는 컴퓨터가 스스로 주변 사물을 인식할 수 있어야 합니다. 정지 신호가 있을 때 속도를 줄이고 초록불이 켜지면 다시 주행을 시작하는 등 주변 환경과 상호작용이 필요한 자율 주행 자동차에 객체 탐지 기술이 사용 됩니다.</p>
<p>객체 탐지 기술은 보안 분야에서 효율적인 자원 관리에도 사용됩니다. 일반적으로 CCTV는 쉬지 않고 기록이 되기 때문에 방대한 양의 메모리가 필요합니다. 허나 객체 탐지 기술과 결합하여 특정 사물이 탐지 되었을 때만 기록을 시작하면 메모리를 효율적으로 사용할 수 있습니다.</p>
<p>이번 장에서는 마스크를 탐지하는 객체 탐지 모델을 구축해보겠습니다. 주어진 이미지를 입력을 받았을 때 얼굴 위치를 탐지하고, 얼굴에 마스크가 씌여져 있는지를 확인하는 모델을 구축해볼 것입니다.</p>
<div class="section" id="id1">
<h2>1.1. 바운딩 박스<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>객체 탐지 모델을 만들기에 앞서, 우선시 되어야 할 과정은 바운딩 박스를 만드는 것 입니다. 객체 탐지 모델에 사용되는 데이터의 크기가 방대하기 때문에, 바운딩 박스를 통하여 객체를 올바르게 탐지하고 딥러닝 과정에서 바운딩 박스 영역만 대상이 되기 때문에, 딥러닝을 효율적으로 수행할 수 있습니다.</p>
<p>바운딩 박스는 특정 사물을 탐지하여 모델을 효율적으로 학습 할 수 있도록 도움을 주는 방법입니다. 객체 탐지 모델에서 바운딩 박스는 타겟 위치를 특정하기 위해 사용됩니다. 타겟 위치를 X와 Y축을 이용하여 사각형으로 표현합니다. 예를 들어, 바운딩 박스 값은 (X 최소값, Y 최소값, X 최대값, Y 최대값)으로 표현이 됩니다.</p>
<p><img alt="" src="https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/raw/master/img/bc1.PNG" /></p>
<ul class="simple">
<li><p>그림 1.2 바운딩 영역 픽셀값으로 지정 (출처: https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection)</p></li>
</ul>
<p>그림 1.2와 같이 X와 Y의 최소값과 최대값 사이의 면적을 바운딩 박스 영역으로 잡습니다. 하지만, 위의 X, Y 값은 픽셀값으로 효율적인 연산을 위해서는 최대값 1로 변환을 해줘야 합니다.</p>
<p><img alt="" src="https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/raw/master/img/bc2.PNG" /></p>
<ul class="simple">
<li><p>그림 1.3 바운딩 영역 백분위로 지정 (출처: https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/raw/master/img/bc2.PNG)</p></li>
</ul>
<p>그림 1.3의 X, Y 값은 각각 X의 최대값 971, Y의 최대값 547을 나눈 값입니다. X의 최소값은 640에서 971을 나누면 0.66이 되는 것입니다. 이렇게 분수화는 효율적인 연산을 위한 과정이라고 볼 수 있지만, 필수적인 과정은 아닙니다.</p>
<p>데이터셋에 따라, 바운딩 박스 값이 메타데이터로 따로 포함된 경우가 있으며, 메타데이터가 없을 경우 따로 코드 구현을 통해 바운딩 박스 지정이 가능합니다. 본 튜토리얼에서 사용하는 <a class="reference external" href="https://www.kaggle.com/andrewmvd/face-mask-detection">Face Mask Detection</a> 데이터셋에는 바운딩 박스가 함께 제공되며, 2장에서 바운딩 박스 도식화를 진행해보겠습니다.</p>
</div>
<div class="section" id="id2">
<h2>1.2. 모델 형태<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>객체 탐지 모델은 크게 One-Stage 모델과 Two-Stage 모델로 구분할 수 있습니다. 각각의 모델 형태에 대해서 알아보도록 하겠습니다.
<img alt="" src="https://drive.google.com/uc?id=1m1tY_ihiDtx2i4hq2qhz5VJwqFZHw8IW" /></p>
<ul class="simple">
<li><p>그림 1.4 객체 탐지 알고리즘 타임라인 (출처:https://jdselectron.tistory.com/101)</p></li>
</ul>
<p>그림 1.4는 객체 탐지 모델의 논문 흐름을 크게 One-Stage Detector, Two-Stage Detector 두 종류로 나누어 보여주고 있습니다. 두 종류의 흐름을 이해하기 위해선 Classification과 Region Proposal의 개념을 이해해야 합니다. Classification은 특정 물체에 대해 어떤 물체인지 분류를 하는 것이고, Region Proposal은 물체가 있을만한 영역을 빠르게 찾아내는 알고리즘 입니다.</p>
<p>그림 1.4에서 가장 먼저 보이는 DetectorNet은 객체 탐지에 CNN을 처음으로 도입한 네트워크로서, 마지막 layer의 softmax를 regression layer로 바꾸어 바운딩 박스를 예측하는 One-Stage 모델입니다.</p>
<p>DetectorNet은 서로 붙어 있는 물체의 경우 하나의 마스크로 구분하기가 어려웠고, 크기가 작은 물체의 경우 탐지하는데 한계가 있었습니다. 또한 물체와 마스크 타입마다 네트워크를 훈련 시켜야 했기 때문에 매우 비효율적이라고 할 수 있습니다.</p>
<p>그림 1.4에 있는 R-CNN의 계열의 구조는 Two-Stage Detector 입니다. Two-Stage Detector은 객체를 검출하는 정확도 측면에서는 좋은 성능을 냈지만, 예측 속도가 느려 실시간 탐지에는 제한됐습니다. 이러한 속도 문제를 해결하기 위해 Classification과 Region Propsal을 동시에 하는 One-Stage Detector가 제안되었습니다. 다음 절에서 One-Stage Detector와 Two-Stage Detector의 구조도를 확인해보도록 하겠습니다.</p>
<div class="section" id="one-stage-detector">
<h3>1.2.1. One-Stage Detector<a class="headerlink" href="#one-stage-detector" title="Permalink to this headline">¶</a></h3>
<p>One-stage Detector는 Classification, Regional Proposal을 동시에 수행하여 결과를 얻는 방법입니다. 그림 1.5와 같이 이미지를 모델에 입력 후, Conv Layer를 사용하여 이미지 특징을 추출합니다.</p>
<p><img alt="" src="https://drive.google.com/uc?id=1850eKsb59NtgQEcM0fXji7cD13TEsDo3" /></p>
<ul class="simple">
<li><p>그림 1.5 One-Stage Detector 구조(출처:https://jdselectron.tistory.com/101)</p></li>
</ul>
</div>
<div class="section" id="two-stage-detector">
<h3>1.2.2. Two-Stage Detector<a class="headerlink" href="#two-stage-detector" title="Permalink to this headline">¶</a></h3>
<p>Two-stage Detector는 Classification, Regional Proposal을 순차적으로 수행하여 결과를 얻는 방법입니다. 그림 1.6과 같이 Region Proposal과 Classification을 순차적으로 실행하는 것을 알 수 있습니다.</p>
<p><img alt="" src="https://drive.google.com/uc?id=1qACO-vEahSiz2Zb5jmAW1jbw94g1ThZO" /></p>
<ul class="simple">
<li><p>그림 1.6 Two-Stage Detector 구조(출처:https://jdselectron.tistory.com/101)</p></li>
</ul>
<p>결과적으로 One-Stage Detector는 비교적 빠르지만 정확도가 낮고, Two-Stage Detector는 비교적 느리지만 정확도가 높습니다.</p>
</div>
</div>
<div class="section" id="id3">
<h2>1.3. 모델 구조<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>One-Stage Detector와 Two-stage Detector 별로 여러 구조가 존재합니다. R-CNN, Fast R-CNN, Faster R-CNN은 Two-Stage Detector이며 YOLO, SSD, RetinaNet은 One-Stage Detector입니다. 각각의 모델 구조 특성에 대해 알아보도록 하겠습니다.</p>
<div class="section" id="r-cnn">
<h3>1.3.1. R-CNN<a class="headerlink" href="#r-cnn" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="https://drive.google.com/uc?id=1qCmgiqH45lkpzADBk3zh29RFPPrRVKC4" /></p>
<ul class="simple">
<li><p>그림 1.8 R-CNN 구조 (출처: Girshick et al. 2014. Rich feature gierarchies for accurate object detection and semantic segmentation)</p></li>
</ul>
<p>R-CNN은 Selective Search를 이용해 이미지에 대한 후보영역(Region Proposal)을 생성합니다. 생성된 각 후보영역을 고정된 크기로 wrapping하여 CNN의 input으로 사용합니다. CNN에서 나온 Feature map으로 SVM을 통해 분류, Regressor을 통해 Bounding-box를 조정합니다. 강제로 크기를 맞추기 위한 wrapping으로 이미지의 변형이나 손실이 일어나고 후보영역만큼 CNN을 돌려야하하기 때문에 큰 저장공간을 요구하고 느리다는 단점이 있습니다.</p>
</div>
<div class="section" id="fast-r-cnn">
<h3>1.3.2. Fast R-CNN<a class="headerlink" href="#fast-r-cnn" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="https://drive.google.com/uc?export=view&amp;id=1zKLOeKylk2SjRMQmfJ3ZJdaJSs0q1fIw" /></p>
<ul class="simple">
<li><p>그림 1.9 Fast R-CNN 구조 (출처: Girshick. ICCV 2015. Fast R-CNN)</p></li>
</ul>
<p>각 후보영역에 CNN을 적용하는 R-CNN과 달리 이미지 전체에 CNN을 적용하여 생성된 Feature map에서 후보영역을 생성합니다. 생성된 후보영역은 RoI Pooling을 통해 고정 사이즈의 Feature vector로 추출합니다. Feature vector에 FC layer를 거쳐 Softmax를 통해 분류, Regressor를 통해 Bounding-box를 조정합니다.</p>
</div>
<div class="section" id="faster-r-cnn">
<h3>1.3.3. Faster R-CNN<a class="headerlink" href="#faster-r-cnn" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="https://drive.google.com/uc?export=view&amp;id=1O5sRVhjcVR8J8zFDhVNwWHmEo069j876" />
<img alt="" src="https://drive.google.com/uc?export=view&amp;id=18PW63VbzIdODeCRGSW0G9UF78Zmd5QY0" /></p>
<ul class="simple">
<li><p>그림 1.10 Faster R-CNN 구조 (출처: Ren et al. 2016. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks)</p></li>
</ul>
<p>Selective Search 부분을 딥러닝으로 바꾼 Region Proposal Network(RPN)을 사용합니다. RPN은 Feature map에서 CNN 연산시 sliding-window가 찍은 지점마다 Anchor-box로 후보영역을 예측합니다. Anchor-box란 미리 지정해놓은 여러 개의 비율과 크기의 Bounding-box입니다. RPN에서 얻은 후보영역을 IoU순으로 정렬하여 Non-Maximum Suppression(NMS) 알고리즘을 통해 최종 후보영역을 선택합니다. 선택된 후보영역의 크기를 맞추기 위해 RoI Pooling을 거치고 이후 Fast R-CNN과 동일하게 진행합니다.</p>
</div>
<div class="section" id="yolo">
<h3>1.3.4. YOLO<a class="headerlink" href="#yolo" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="https://drive.google.com/uc?export=view&amp;id=1mVIx26ewRcNab82TGkFj1ODnvPSoQjoD" /></p>
<ul class="simple">
<li><p>그림 1.11 YOLO 구조 (출처: Redmon et al. 2016. You Only Look Once: Unified, Real-Time Object Detection)</p></li>
</ul>
<p>Bouning-box와 Class probability를 하나의 문제로 간주하여 객체의 종류와 위치를 한번에 예측합니다.이미지를 일정 크기의 그리드로 나눠 각 그리드에 대한 Bounding-box를 예측합니다. Bounding-box의 confidence score와 그리드셀의 class score의 값으로 학습하게 됩니다. 간단한 처리과정으로 속도가 매우 빠르지만 작은 객체에 대해서는 상대적으로 정확도가 낮습니다.</p>
</div>
<div class="section" id="ssd">
<h3>1.3.5. SSD<a class="headerlink" href="#ssd" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="https://drive.google.com/uc?export=view&amp;id=11kZDrVy5qi4VIAPXfGLmaGV5l_5h68rO" /></p>
<ul class="simple">
<li><p>그림 1.12 SSD 구조 (출처: Liu et al. 2016. SSD: Single Shot MultiBox Detector)</p></li>
</ul>
<p>각 Covolutional Layer 이후에 나오는 Feature map마다 Bounding-box의 Class 점수와 Offset(위치좌표)를 구하고, NMS 알고리즘을 통해 최종 Bounding-box를 결정합니다. 이는 각 Feature map마다 스케일이 다르기 때문에 작은 물체와 큰 물체를 모두 탐지할 수 있다는 장점이 있습니다.</p>
</div>
<div class="section" id="retinanet">
<h3>1.3.6. RetinaNet<a class="headerlink" href="#retinanet" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="https://github.com/Pseudo-Lab/Tutorial-Book/blob/master/pics/ch1img13.PNG?raw=true" /></p>
<ul class="simple">
<li><p>그림 1.13 Focal Loss (출처: Lin et al. 2018. Focal Loss for Dense Object Detection)</p></li>
</ul>
<p>RetinaNet은 모델 학습시 계산하는 손실 함수(loss function)에 변화를 주어 기존 One-Stage Detector들이 지닌 낮은 성능을 개선했습니다. One-Stage Detector는 많게는 십만개 까지의 후보군 제시를 통해 학습을 진행합니다. 그 중 실제 객체인 것은 일반적으로 10개 이내 이고, 다수의 후보군이 background 클래스로 잡힙니다. 상대적으로 분류하기 쉬운 background 후보군들에 대한 loss값을 줄여줌으로써 분류하기 어려운 실제 객체들의 loss 비중을 높이고, 그에 따라 실제 객체들에 대한 학습에 집중하게 합니다. RetinaNet은 속도 빠르면서 Two-Stage Detector와 유사한 성능을 보입니다</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs\object_detection"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../index.html" title="previous page">파이토치를 활용한 딥러닝 튜토리얼 (Deep Learning Tutorials using PyTorch)</a>
    <a class='right-next' id="next-link" href="Ch2%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%ED%83%90%EC%83%89.html" title="next page">2. 데이터 탐색</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By PseudoLab Tutorial Team<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>
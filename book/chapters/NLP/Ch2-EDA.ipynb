{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch2-EDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbKu47wDI3WnueMZ47SLiq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55876bba14a74ed08ab3cca918d0d3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ad8bfb8e86d48dfb3a6ba6eedbe87a9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b25aa26f95d548a9a0170856ad310ca5",
              "IPY_MODEL_1fb68017fd424709a3a6bb18743c2f45"
            ]
          }
        },
        "4ad8bfb8e86d48dfb3a6ba6eedbe87a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b25aa26f95d548a9a0170856ad310ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38528bb95ef84777b65c3a8155e4f486",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a9fa1bf24fe4948aafa169ae9085a21"
          }
        },
        "1fb68017fd424709a3a6bb18743c2f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c02d231a0bbe42438b930a4b85c6a5e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 2.84MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0356e679e3b24a0daea1403a4db94b72"
          }
        },
        "38528bb95ef84777b65c3a8155e4f486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a9fa1bf24fe4948aafa169ae9085a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c02d231a0bbe42438b930a4b85c6a5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0356e679e3b24a0daea1403a4db94b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce3e610f340e4126bd536414d52a9430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6eba1f126b2448c49481db35492f0056",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1132e8a445d4b9aac1f1d51e4ef27dd",
              "IPY_MODEL_5798cf012644463c9055713b24332543"
            ]
          }
        },
        "6eba1f126b2448c49481db35492f0056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1132e8a445d4b9aac1f1d51e4ef27dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ba165b274fe4640a567b112366afe04",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_efe0525b071d4ab3a4fe5d51492e75df"
          }
        },
        "5798cf012644463c9055713b24332543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a28b24a6f754881b7aa66c24c047ac9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 2.00MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_027532b86b9948cb8472270372957e8d"
          }
        },
        "8ba165b274fe4640a567b112366afe04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "efe0525b071d4ab3a4fe5d51492e75df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a28b24a6f754881b7aa66c24c047ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "027532b86b9948cb8472270372957e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9f194240d28445b919af67f69b9239f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aa65f12233ba40578367b5c416a98b65",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b54e149c6154531b4a030a64b4fc3a8",
              "IPY_MODEL_35845085ce11409fb05b80666798a13d"
            ]
          }
        },
        "aa65f12233ba40578367b5c416a98b65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b54e149c6154531b4a030a64b4fc3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a62d98359554d24b7615d9c3622a9ab",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03e28307af124cfda60f94fea6f61f88"
          }
        },
        "35845085ce11409fb05b80666798a13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_471877dd6db14d5da9b304b757f7bf2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [01:10&lt;00:00, 9.41B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99b84a050a9b4ffdb822c16fecadc1dd"
          }
        },
        "4a62d98359554d24b7615d9c3622a9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03e28307af124cfda60f94fea6f61f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "471877dd6db14d5da9b304b757f7bf2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99b84a050a9b4ffdb822c16fecadc1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08d79dc449154f6189ca8f48296221e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aec04ba2a9ac48d4a3d8b2a3514c79f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9fe5dd092b64274985f5e6f23fbf05f",
              "IPY_MODEL_9a36e27a9e3d4693a0e503d24eb349e1"
            ]
          }
        },
        "aec04ba2a9ac48d4a3d8b2a3514c79f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9fe5dd092b64274985f5e6f23fbf05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_169a2b164d89432197cd4374c87dda27",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a4cbd4c9b844ddda63239731b260384"
          }
        },
        "9a36e27a9e3d4693a0e503d24eb349e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_161df82401824cf497fa30bc1c8f96e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:13&lt;00:00, 41.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1dd5715c429f43ebb2e1056df0449498"
          }
        },
        "169a2b164d89432197cd4374c87dda27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a4cbd4c9b844ddda63239731b260384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "161df82401824cf497fa30bc1c8f96e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1dd5715c429f43ebb2e1056df0449498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ohw7wEzRr_z"
      },
      "source": [
        "# 2. 데이터 탐색과 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjLqioWfUWPU"
      },
      "source": [
        "이전 장에서는 Question Generation Task의 개념과 모델, 평가지표 등에 대해 알아보았습니다. 이번 장에서는 실습에 사용할 데이터셋을 확인해보도록 하겠습니다. \n",
        "\n",
        "NLP 튜토리얼에서는 에세이 데이터를 활용해 학습자들을 위한 영어 문제를 생성하는 모델을 만들어 볼 것입니다. 구체적으로 3개의 문제를 만들어 볼 것입니다. 왜 에세이냐? -> 개인의 생각이 들어간 수필인데 이것을 쓰면 이러이러한 이유에서 좋다  NUS는 세계 몇 위 대학이고, 학생들 수준이 상당히 높아 에세이 수준도 높다. RC로 적합하다 또 WI Locness는 상위 수준의 학생들의 에세이만 고를 꺼기 때문에, 괜찮다. \n",
        "\n",
        "문제를 모두 4지선다 문제다. \n",
        "왜 4지선다 문제냐? 평가 쉽고, blah blah blah\n",
        "\n",
        "지문 내용 기반 참 거짓 문제, WH-5 문제 생성할거다. \n",
        "\n",
        "참 거짓 문제란 ~~\n",
        "\n",
        "WH-5 문제란 ~~ \n",
        "\n",
        "grammar 문제는 실제 GEC task에 사용되는 데이터셋에서 틀린 grammar들 위주로 구성했으므로, 실제 ESL 학생드리 헷갈려하는 문제 위주로 grammar 문제를 구성해서 유효성을 확보함. \n",
        "\n",
        "2.1절에서는 데이터를 다운로드 받는 방법을 살펴보겠습니다. 2.2절에서는 데이터를 시각화 해볼 것이며, 2.3절에서는 matplotlib.pyplot 에서 제공하는 subplots 함수를 활용해 여러 이미지를 하나의 출력 창에 시각화 하는 방법을 알아보겠습니다. 마지막으로 2.4절에서는 이미지 전처리를 통해 픽셀값에 정규화(normalization)을 진행해보겠습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL-OzDV-wb8o"
      },
      "source": [
        "## 2.1 2014 CoNLL Shared Task Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWqElsQsXRC7"
      },
      "source": [
        "Conference on Computational Natural Language Learning (CoNLL)은 매년 자연어처리 관련 기술에 대해 논하는 학회입니다. 논문 발표와 더불어 매년 자연어 처리와 관련된 Shared Task를 운영하고 있습니다. Shared Task는 특정 기간 동안 여러 팀이 참가해서 주최측에서 제시한 문제를 해결하는 과제로써, 데이터 경진대회와 유사합니다. CoNLL에서 운영한 모든 Shared Task는 [https://conll.org/previous-tasks](https://conll.org/previous-tasks)에서 확인 가능합니다. \n",
        "\n",
        "2013년, 2014년에는 Grammer Error Correction(GEC) 과제를 Shared Task로 운영했습니다. GEC는 에세이내의 문법 오류 위치를 탐지한 후 올바른 단어로 수정하는 알고리즘을 구축하는 과제였습니다.\n",
        "\n",
        "이번 튜토리얼에서 사용할 데이터는 CoNLL Shared Task가 종료된 후 주최측에서 공개한 라벨링된 시험 데이터셋 입니다. Shared Task에서 공식적으로 사용된 훈련 데이터인 NUCLE corpus는 [NUS Natural Language Processing Group](https://www.comp.nus.edu.sg/~nlp/corpora.html)에 신청서를 보내야 얻을 수 있지만, 시험 데이터셋은 누구나 열람할 수 있게 공개가 되어 있기 때문입니다. \n",
        "\n",
        "2014년도 GEC의 시험 데이터셋은 총 50개의 에세이로 이뤄져 있습니다. 25명의 비영어권 NUS 학생(Non-native speaker of English)이 표 2.1에 있는 2개의 주제에 대해 각각 하나의 에세이를 제출해서 총 50개 입니다. 해당 에세이에 대해 2명의 영어 원어민이 문법 교정, 즉 데이터 라벨링을 실시했습니다. \n",
        "\n",
        "| ID   | Prompt                                                       |\n",
        "| ---- | ------------------------------------------------------------ |\n",
        "| 1    | “The decision to undergo genetic testing can only be made by the individual at risk for a disorder. <br/> Once a test has been conducted and the results are known, however, a new, family-related ethical dilemma is born: <br/> Should a carrier of a known genetic risk be obligated to tell his or her relatives?” <br/> Respond to the question above, supporting your argument with concrete examples. |\n",
        "| 2    | While social media sites such as Twitter and Facebook can connect us closely to people in many parts of the world, <br/> some argue that the reduction in face-to-face human contact affects interpersonal skills. <br/> Explain the advantages and disadvantages of using social media in your daily life/society |\n",
        "\n",
        "- 표 2.1 시험 데이터셋 구축에 사용한 에세이 주제 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX75CpsCjPFV"
      },
      "source": [
        "### 2.1.1 CoNLL 데이터 탐색"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20LMGkryXatI"
      },
      "source": [
        "먼저 아래 코드를 활용해 https://www.comp.nus.edu.sg/~nlp/conll14st.html 에 공개된 시험 데이터셋을 Colab환경에 다운로드 받습니다. 리눅스의 `wget`명령어를 활용해 제공된 다운로드 링크로 부터 `tar.gz`파일을 받을 수 있습니다. 이때 `-O` 옵션을 주어 파일명을 `conll2014.tar.gz`로 변경해서 다운로드 받아보도록 하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxkaQ3YIblgH",
        "outputId": "74695379-bf85-40b3-c2c8-982e2e8f057e"
      },
      "source": [
        "!wget -O 'conll2014.tar.gz' https://www.comp.nus.edu.sg/~nlp/conll14st/conll14st-test-data.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-08 10:45:02--  https://www.comp.nus.edu.sg/~nlp/conll14st/conll14st-test-data.tar.gz\n",
            "Resolving www.comp.nus.edu.sg (www.comp.nus.edu.sg)... 45.60.31.225\n",
            "Connecting to www.comp.nus.edu.sg (www.comp.nus.edu.sg)|45.60.31.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 643482 (628K) [application/x-gzip]\n",
            "Saving to: ‘conll2014.tar.gz’\n",
            "\n",
            "conll2014.tar.gz    100%[===================>] 628.40K   347KB/s    in 1.8s    \n",
            "\n",
            "2021-04-08 10:45:06 (347 KB/s) - ‘conll2014.tar.gz’ saved [643482/643482]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14PbgErScAjw"
      },
      "source": [
        "![](https://github.com/Pseudo-Lab/Tutorial-Book/blob/master/book/pics/NLP-ch2img01.JPG?raw=true)\n",
        "- 그림 2.1 다운로드 된 tar.gz 파일\n",
        "\n",
        "Colab 파일 경로에 그림 2.1과 같이 `conll2014.tar.gz`파일이 다운로드 된것을 확인할 수 있습니다. 다음으로는 해당 파일을 리눅스의 `tar`명령어를 활용해 압축 해제 하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbPfFoMe145"
      },
      "source": [
        "# 압축 풀고\n",
        "!tar -xf conll2014.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KTvXe1QYV8b"
      },
      "source": [
        "압축이 해제되면 `conll14st-test-data`폴더가 생성된 것을 확인할 수 있습니다. 해당 폴더는 그림 2.2와 같이 구성돼 있습니다. \n",
        "\n",
        "![](https://github.com/Pseudo-Lab/Tutorial-Book/blob/master/book/pics/NLP-ch2img02.JPG?raw=true)\n",
        "\n",
        "그림 2.2 `conll14st-test-data` 폴더 구조\n",
        "\n",
        "각 폴더가 의미하는 내용은 다음과 같습니다. \n",
        "\n",
        "- `alt`: 참가팀에서 제출한 대체 답안이 저장된 폴더\n",
        "- `noalt`: 주최측의 답안이 저장된 폴더\n",
        "- `scripts`: 주최측에서 제공한 데이터 전처리 스크립트\n",
        "\n",
        "2014 CoNLL Shared Task에서 참가자가 맞춰야 하는 타겟은, 올바른 문법 용어 입니다. 하지만 이러한 문법 용어는 여러개가 존재할 수 있기 때문에, 주최측의 Annotator들이 모두 커버할 수 없을 수 있습니다. 이러한 점을 고려해 대회 종료 후 참가팀으로 부터 Alternative Answer를 제출 받았고, 총 3팀이 제출해서 해당 팀들의 답안이 `alt` 폴더에 저장돼 있습니다. \n",
        "\n",
        "scripts는 파이썬 2.6.4에서 원할히 작동합니다. 하지만 최근에는 대부분 파이썬 3으로 교육을 하기 때문에 튜토리얼에 scripts파일로 튜토리얼을 구성하기 적합하지 않습니다. 또한, scripts에 있는 코드를 배워 CoNLL Shared Task에 한정된 코드를 배워보는 것 보다는, 일반적으로 사용되는 BeautifulSoup, Numpy 등의 패키지로 직접 전처리 하는 과정을 연습해보면 좋을 것 같다는 판단이 들어, 본 튜토리얼에서는 scripts에서 제공한 파일을 쓰지 않고, 자체적으로 전처리 과정을 구성해보겠습니다. 전처리 하는 과정을 직접 익혀봄으로써 다른 데이터셋이 주어졌을 때 유동적으로 대처하는 능력이 배양되길 바랍니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2WGGnsweiCl"
      },
      "source": [
        "먼저 `BeautifulSoup` 라이브러리를 불러옵니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYv6DLh3wlyD"
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDd5CF_xen1T"
      },
      "source": [
        "`noalt`폴더 내에 있는 `official-2014.0.sgml`파일을 `open()` 함수를 활용해 엽니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP1UolDQbKwt"
      },
      "source": [
        "# 파일 열고 annotator 1에 의해 라벨링 된 파일\n",
        "sgml_file = open('conll14st-test-data/noalt/official-2014.0.sgml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlIiYZ_dkwt5"
      },
      "source": [
        "그 후 `read()` 함수를 활용해 `official-2014.0.sgml` 파일의 내용물을 읽어서 `conll` 변수에 저장합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ftd0YJzbN-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff528fd9-d457-4bf5-ad93-907971aecf03"
      },
      "source": [
        "# 파일 읽고\n",
        "conll = sgml_file.read()\n",
        "sgml_file.close()\n",
        "type(conll)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29MbW4-hlo1_"
      },
      "source": [
        "`conll` 변수 타입을 확인해보니 문자열로 저장된 것을 확인할 수 있습니다. `conll` 변수에 어떤 문자열이 저장됐는지 확인해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7NZwU2XlI72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "2aa72220-7951-4cfe-8222-1d7eb3e2ccf4"
      },
      "source": [
        "conll[:2500]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<DOC nid=\"1\">\\n<TEXT>\\n<TITLE>\\nKeeping the Secret of Genetic Testing\\n</TITLE>\\n<P>\\nWhat is genetic risk? Genetic risk refers more to your chance of inheriting a disorder or disease. People get certain disease because of genetic changes. How much a genetic change tells us about your chance of developing a disorder is not always clear. If your genetic results indicate that you have gene changes associated with an increased risk of heart disease, it does not mean that you definitely will develop heart disease. The opposite is also true. If your genetic results show that you do not have changes associated with an increased risk of heart disease, it is still possible that you develop heart disease. However for some rare diseases, people who have certain gene changes are guaranteed to develop the disease. When we are diagonosed out with certain genetic disease, are we suppose to disclose this result to our relatives? My answer is no.\\n</P>\\n<P>\\nOn one hand, we do not want this potential danger causing firghtenning affects in our families\\' later lives. When people around us know that we got certain disease, their altitudes will be easily changed, whether caring us too much or keeping away from us. And both are not what we want since most of us just want to live as normal people. Surrounded by such concerns, it is very likely that we are distracted to worry about these problems. It is a concern that will be with us during our whole life, because we will never know when the \\'\\'potential bomb\\'\\' will explode.\\n</P>\\n<P>\\nOn the other hand, if there are ways can help us to control or cure the disease, we can going through thses process from the scope of the whole family. For an example, if exercising is helpful for family potential disease, we can always look for more chances for the family to go exercise. And we keep track of all family members health conditions. At the same time, we are prepared to know when there are other members got this disease.\\n</P>\\n<P>\\nHere I want to share Forest\\'view on this issue. Although some people feel that an individual who is found to carry a dominant gene for Huntington\\'s disease has an ethical obligation to disclose that fact to his or her siblings, there currently is no legal requirement to do so. In fact, requiring someone to communicate his or her own genetic risk to family members who are therefore also at risk is considered by many to be ethically dubious.\"\\n</P>\\n<P>\\nNothing is absolute right or wrong. If certain disease genetic test is v'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9grNs-8t16eN"
      },
      "source": [
        "보시다 시피 `conll`변수 내에 저장된 문자열에 다양한 태그(tag)들이 존재하는 것을 확인할 수 있습니다. `<DOC>`, `<TEXT>`, `<TITLE>` 등 의 태그들이 존재합니다. 이것은 Markup Language를 표현하는 방식과 같습니다. 사실 파일 확장자 명에 있는 `sgml`가 Standard Generalized Markup Language (SGML)의 약자입니다. SGML은 HTML등의 Markup Language가 따라야 하는 기준을 제시하는 메타 언어입니다. \n",
        "\n",
        "그러므로 해당 `conll`변수는 파이썬에서 HTML내의 데이터를 추출할 때 사용하는 `BeautifulSoup` 라이브러리를 활용해 처리해보겠습니다. 아래 코드처럼 Markup Language 형태의 정보가 저장된 `conll`변수를 첫번째 파라미터로 넘기고, 두번째 파라미터에는 데이터 처리시 사용할 `parser`를 명시합니다. 일반적으로 `BeautifulSoup`에서 제공하는 `html.parser`를 사용하기도 하지만, [공식 문서](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser)에서는 속도를위해 `lxml`사용하는 것을 추천하므로, 본 튜토리얼에서도 `lxml`을 활용해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hti6nGpcbRFt"
      },
      "source": [
        "# 파싱하고\n",
        "conllsoup = BeautifulSoup(conll, 'lxml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxvPlF9Abhsk",
        "outputId": "433c51a9-a830-4b7a-b29f-0adef9839b61"
      },
      "source": [
        "type(conllsoup)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bs4.BeautifulSoup"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gkEk1FFOkKa"
      },
      "source": [
        "`BeautifulSoup`객체로 변환된것을 확인할 수 있습니다. 가장 먼저 CoNLL 데이터셋 내에 어떤 태그들이 존재하는지 확인해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSB9KA6pbXbg"
      },
      "source": [
        "tag_names = set([tag.name for tag in conllsoup.find_all()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh3X7uCuPAbJ"
      },
      "source": [
        "List Comprehension을 활용해 `conllsoup`내에 있는 모든 태그들을 `list` 내부에 저장합니다. 그 중에는 중복되는 태그명들도 있을 수 있으므로, 고유의 태그명만 확인하기 위해 `set()`함수를 사용해 `list`를 `set` 형태로 변환시켜 줍니다. 파이썬에서 `set`은 중복되는 원소를 가질 수 없기 때문에, 중복 원소가 있는 경우 하나의 원소만 남겨두고 나머지는 제거하게 됩니다. \n",
        "\n",
        "`tag_names`의 있는 고유 태그들을 확인해보면 아래와 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJNi0WBVba0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406e7c7f-1ec6-44eb-a1ce-a4a6ee786bf4"
      },
      "source": [
        "tag_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'annotation',\n",
              " 'body',\n",
              " 'comment',\n",
              " 'correction',\n",
              " 'doc',\n",
              " 'html',\n",
              " 'mistake',\n",
              " 'p',\n",
              " 'text',\n",
              " 'title',\n",
              " 'type'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWj3rPNkiNfw",
        "outputId": "d0ffb24d-e346-4f3c-b916-c8d926690a26"
      },
      "source": [
        "conllsoup.find('doc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<doc nid=\"1\">\n",
              "<text>\n",
              "<title>\n",
              "Keeping the Secret of Genetic Testing\n",
              "</title>\n",
              "<p>\n",
              "What is genetic risk? Genetic risk refers more to your chance of inheriting a disorder or disease. People get certain disease because of genetic changes. How much a genetic change tells us about your chance of developing a disorder is not always clear. If your genetic results indicate that you have gene changes associated with an increased risk of heart disease, it does not mean that you definitely will develop heart disease. The opposite is also true. If your genetic results show that you do not have changes associated with an increased risk of heart disease, it is still possible that you develop heart disease. However for some rare diseases, people who have certain gene changes are guaranteed to develop the disease. When we are diagonosed out with certain genetic disease, are we suppose to disclose this result to our relatives? My answer is no.\n",
              "</p>\n",
              "<p>\n",
              "On one hand, we do not want this potential danger causing firghtenning affects in our families' later lives. When people around us know that we got certain disease, their altitudes will be easily changed, whether caring us too much or keeping away from us. And both are not what we want since most of us just want to live as normal people. Surrounded by such concerns, it is very likely that we are distracted to worry about these problems. It is a concern that will be with us during our whole life, because we will never know when the ''potential bomb'' will explode.\n",
              "</p>\n",
              "<p>\n",
              "On the other hand, if there are ways can help us to control or cure the disease, we can going through thses process from the scope of the whole family. For an example, if exercising is helpful for family potential disease, we can always look for more chances for the family to go exercise. And we keep track of all family members health conditions. At the same time, we are prepared to know when there are other members got this disease.\n",
              "</p>\n",
              "<p>\n",
              "Here I want to share Forest'view on this issue. Although some people feel that an individual who is found to carry a dominant gene for Huntington's disease has an ethical obligation to disclose that fact to his or her siblings, there currently is no legal requirement to do so. In fact, requiring someone to communicate his or her own genetic risk to family members who are therefore also at risk is considered by many to be ethically dubious.\"\n",
              "</p>\n",
              "<p>\n",
              "Nothing is absolute right or wrong. If certain disease genetic test is very accurate and it is unavoidable and necessary to get treatment and known by others, it is OK to disclose the result. Above all, life is more important than secret.\n",
              "</p>\n",
              "</text>\n",
              "<annotation teacher_id=\"8\">\n",
              "<mistake end_off=\"46\" end_par=\"1\" start_off=\"42\" start_par=\"1\">\n",
              "<type>ArtOrDet</type>\n",
              "<correction></correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"125\" end_par=\"1\" start_off=\"118\" start_par=\"1\">\n",
              "<type>Nn</type>\n",
              "<correction>diseases</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"627\" end_par=\"1\" start_off=\"620\" start_par=\"1\">\n",
              "<type>Trans</type>\n",
              "<correction>However,</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"751\" end_par=\"1\" start_off=\"740\" start_par=\"1\">\n",
              "<type>Mec</type>\n",
              "<correction>diagnosed</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"754\" end_par=\"1\" start_off=\"751\" start_par=\"1\">\n",
              "<type>Prep</type>\n",
              "<correction></correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"783\" end_par=\"1\" start_off=\"776\" start_par=\"1\">\n",
              "<type>Nn</type>\n",
              "<correction>diseases</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"58\" end_par=\"2\" start_off=\"50\" start_par=\"2\">\n",
              "<type>Wci</type>\n",
              "<correction>having</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"70\" end_par=\"2\" start_off=\"58\" start_par=\"2\">\n",
              "<type>Mec</type>\n",
              "<correction>frightening</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"78\" end_par=\"2\" start_off=\"71\" start_par=\"2\">\n",
              "<type>Wform</type>\n",
              "<correction>effects</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"147\" end_par=\"2\" start_off=\"144\" start_par=\"2\">\n",
              "<type>Wci</type>\n",
              "<correction>have</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"163\" end_par=\"2\" start_off=\"156\" start_par=\"2\">\n",
              "<type>Nn</type>\n",
              "<correction>diseases</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"180\" end_par=\"2\" start_off=\"171\" start_par=\"2\">\n",
              "<type>Mec</type>\n",
              "<correction>attitude</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"203\" end_par=\"2\" start_off=\"186\" start_par=\"2\">\n",
              "<type>Vform</type>\n",
              "<correction>easily change</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"219\" end_par=\"2\" start_off=\"213\" start_par=\"2\">\n",
              "<type>Prep</type>\n",
              "<correction>caring for</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"412\" end_par=\"2\" start_off=\"410\" start_par=\"2\">\n",
              "<type>Trans</type>\n",
              "<correction>and</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"516\" end_par=\"2\" start_off=\"512\" start_par=\"2\">\n",
              "<type>Vt</type>\n",
              "<correction></correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"36\" end_par=\"3\" start_off=\"32\" start_par=\"3\">\n",
              "<type>Ssub</type>\n",
              "<correction>ways that</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"93\" end_par=\"3\" start_off=\"88\" start_par=\"3\">\n",
              "<type>Vform</type>\n",
              "<correction>go</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"107\" end_par=\"3\" start_off=\"102\" start_par=\"3\">\n",
              "<type>Mec</type>\n",
              "<correction>these</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"115\" end_par=\"3\" start_off=\"108\" start_par=\"3\">\n",
              "<type>Nn</type>\n",
              "<correction>processes</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"158\" end_par=\"3\" start_off=\"156\" start_par=\"3\">\n",
              "<type>Rloc-</type>\n",
              "<correction></correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"196\" end_par=\"3\" start_off=\"193\" start_par=\"3\">\n",
              "<type>V0</type>\n",
              "<correction>reducing</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"279\" end_par=\"3\" start_off=\"277\" start_par=\"3\">\n",
              "<type>Wci</type>\n",
              "<correction>do</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"290\" end_par=\"3\" start_off=\"288\" start_par=\"3\">\n",
              "<type>Rloc-</type>\n",
              "<correction></correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"293\" end_par=\"3\" start_off=\"290\" start_par=\"3\">\n",
              "<type>Trans</type>\n",
              "<correction>so</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"423\" end_par=\"3\" start_off=\"420\" start_par=\"3\">\n",
              "<type>Ssub</type>\n",
              "<correction>who have got</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"28\" end_par=\"4\" start_off=\"21\" start_par=\"4\">\n",
              "<type>Npos</type>\n",
              "<correction>Forests's</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"19\" end_par=\"5\" start_off=\"11\" start_par=\"5\">\n",
              "<type>Wform</type>\n",
              "<correction>absolutely</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"46\" end_par=\"5\" start_off=\"39\" start_par=\"5\">\n",
              "<type>ArtOrDet</type>\n",
              "<correction>a certain</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"54\" end_par=\"5\" start_off=\"47\" start_par=\"5\">\n",
              "<type>Rloc-</type>\n",
              "<correction></correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"147\" end_par=\"5\" start_off=\"142\" start_par=\"5\">\n",
              "<type>Wci</type>\n",
              "<correction>tell</correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"150\" end_par=\"5\" start_off=\"148\" start_par=\"5\">\n",
              "<type>Prep</type>\n",
              "<correction></correction>\n",
              "</mistake>\n",
              "<mistake end_off=\"237\" end_par=\"5\" start_off=\"231\" start_par=\"5\">\n",
              "<type>Nn</type>\n",
              "<correction>secrets</correction>\n",
              "</mistake>\n",
              "</annotation>\n",
              "</doc>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkiCMTIiP_LM"
      },
      "source": [
        "각각의 태그와 태그 내의 속성이 의미하는 바는 다음과 같습니다. \n",
        "\n",
        "- `annotation`: `text`의 모든 문법 오류를 저장한 태그, `mistake`의 부모 태그\n",
        "    - `teacher_id`: 문법 교정한 선생님 고유 번호\n",
        "- `body`: 모든 태그 정보가 저장된 부모 태그\n",
        "- `comment`: \n",
        "- `correction`: \n",
        "- `doc`: `text`, `title`, `annotation`정보가 저장된 부모 태그\n",
        "    - `nid`: 문서 고유 번호\n",
        "- `html`: `body`의 부모 태그\n",
        "- `mistake`: `type`, `comment`, `correction` 정보가 저장된 부모 태그\n",
        "    - `end_off`: 오류가 끝나는 문자열 위치\n",
        "    - `end_par`: 오류가 끝나는 문단 위치\n",
        "    - `start_off`: 오류가 시작하는 문자열 위치\n",
        "    - `start_par`: 오류가 끝나는 문단 위치\n",
        "- `p`: 에세이의 각 문단이 저장된 태그\n",
        "- `text`: 학생이 쓴 에세이가 저장된 태그, `title`과 `p`의 부모 태그\n",
        "- `title`: 에세이의 제목이 저장된 태그\n",
        "- `type`: 문법 오류 유형이 저장된 태그\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9r83Yt9idb1"
      },
      "source": [
        "해당 에세이를 독해 문제 지문으로 활용하기 위해선 탐지된 문법 오류를 모두 교정할 필요가 있습니다. 문법 오류가 발생한 위치 정보와 해당 단어를 대체하기 위한 올바른 문법 단어 정보를 알고 있으므로, 적절한 알고리즘을 활용해 에세이내의 모든 문법 오류를 대체할 수 있습니다. 해당 과정을 2.1.2절에서 확인해보겠습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdgg8rRMjXgs"
      },
      "source": [
        "### 2.1.2 CoNLL 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATGCmF8mjcik"
      },
      "source": [
        "먼저 `mistake` 태그에 담긴 정보들을 확인해보겠습니다. `BeautifulSoup`객체의 `find('태그')` 함수를 사용하면 가장 첫번째로 나오는 `태그`를 반환해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6GEjZFRT-8H",
        "outputId": "097bd027-97b7-4064-da86-7c3efc516008"
      },
      "source": [
        "conllsoup.find('mistake')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mistake end_off=\"46\" end_par=\"1\" start_off=\"42\" start_par=\"1\">\n",
              "<type>ArtOrDet</type>\n",
              "<correction></correction>\n",
              "</mistake>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktXrtlRKbK7h"
      },
      "source": [
        "`start_par`와 `end_par`는 각각 `text`내에서 몇번째 문단에 문법 오류가 존재하는지 나타내고, `start_off`와 `end_off`는 해당 문단에서 몇번째 문자열에 문법 오류가 존재하는지 나타냅니다. 가령 위 예시에서는 첫번째 문단의 [42:46]위치에 있는 문자열이 문법 오류를 지니는 것입니다. \n",
        "\n",
        "`type`은 문법 오류의 종류를 나타내는데, GEC문제라면 관심있게 봐야하는 태그이지만, 본 튜토리얼에서는 문법 오류를 올바른 단어로 대체해서 사용하는 것이 목적이므로 어떤 문법 오류 종류가 존재하는지 세부적으로 확인하지 않겠습니다. 궁금하신 분께서는 참고문헌 [1]을 참고하시기 바랍니다. \n",
        "\n",
        "`correction`은 문법 오류를 고치기 위해서 사용해야 하는 단어를 뜻합니다. 위 예시에서는 값이 없으므로, 이 뜻은 단어를 삭제해야 문법 오류가 교정된다는 뜻입니다. \n",
        "\n",
        "아래 코드를 확인해 어떤 단어인지 확인해보겠습니다. `text`태그에 존재하는 요소를 확인해보겠습니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le2Si9wCbKEo",
        "outputId": "ca4f2f3b-7d10-41c1-91b2-d41a2fdc7572"
      },
      "source": [
        "conllsoup.find('text')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<text>\n",
              "<title>\n",
              "Keeping the Secret of Genetic Testing\n",
              "</title>\n",
              "<p>\n",
              "What is genetic risk? Genetic risk refers more to your chance of inheriting a disorder or disease. People get certain disease because of genetic changes. How much a genetic change tells us about your chance of developing a disorder is not always clear. If your genetic results indicate that you have gene changes associated with an increased risk of heart disease, it does not mean that you definitely will develop heart disease. The opposite is also true. If your genetic results show that you do not have changes associated with an increased risk of heart disease, it is still possible that you develop heart disease. However for some rare diseases, people who have certain gene changes are guaranteed to develop the disease. When we are diagonosed out with certain genetic disease, are we suppose to disclose this result to our relatives? My answer is no.\n",
              "</p>\n",
              "<p>\n",
              "On one hand, we do not want this potential danger causing firghtenning affects in our families' later lives. When people around us know that we got certain disease, their altitudes will be easily changed, whether caring us too much or keeping away from us. And both are not what we want since most of us just want to live as normal people. Surrounded by such concerns, it is very likely that we are distracted to worry about these problems. It is a concern that will be with us during our whole life, because we will never know when the ''potential bomb'' will explode.\n",
              "</p>\n",
              "<p>\n",
              "On the other hand, if there are ways can help us to control or cure the disease, we can going through thses process from the scope of the whole family. For an example, if exercising is helpful for family potential disease, we can always look for more chances for the family to go exercise. And we keep track of all family members health conditions. At the same time, we are prepared to know when there are other members got this disease.\n",
              "</p>\n",
              "<p>\n",
              "Here I want to share Forest'view on this issue. Although some people feel that an individual who is found to carry a dominant gene for Huntington's disease has an ethical obligation to disclose that fact to his or her siblings, there currently is no legal requirement to do so. In fact, requiring someone to communicate his or her own genetic risk to family members who are therefore also at risk is considered by many to be ethically dubious.\"\n",
              "</p>\n",
              "<p>\n",
              "Nothing is absolute right or wrong. If certain disease genetic test is very accurate and it is unavoidable and necessary to get treatment and known by others, it is OK to disclose the result. Above all, life is more important than secret.\n",
              "</p>\n",
              "</text>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gD2PHMvduwD"
      },
      "source": [
        "`text`태그 내에는 `title`과 `p`태그가 존재합니다. `title`은 해당 에세이의 제목, `p`는 문단을 나타냅니다. 앞서 살펴본 `start_par`과 `end_par`의 번호는 `text`내에 존재하는 요소들에 하나씩 대응 되며, `title`을 포함해서 번호를 매깁니다. 즉, 위 예시에서 `start_par`가 `end_par`이 모두 0이면 `Keeping the Secret of Genetic Testing`에 문법 오류가 존재한다는 뜻이며, 1이면은 첫번재 `p`태그에서 문법 오류가 존재한다는 뜻입니다. `text`내에 `title`태그가 없고 `p`태그만 있다면 `start_par`/`end_par`가 0일 때 첫번째 `p`태그를 가르키게 됩니다. \n",
        "\n",
        "`text`내의 내용을 태그 단위로 접근할 수 있게 전처리를 해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "VCnn2Z0kgHau",
        "outputId": "104aaaa2-8738-4757-9329-3094dd872908"
      },
      "source": [
        "conllsoup.find('text').text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nKeeping the Secret of Genetic Testing\\n\\n\\nWhat is genetic risk? Genetic risk refers more to your chance of inheriting a disorder or disease. People get certain disease because of genetic changes. How much a genetic change tells us about your chance of developing a disorder is not always clear. If your genetic results indicate that you have gene changes associated with an increased risk of heart disease, it does not mean that you definitely will develop heart disease. The opposite is also true. If your genetic results show that you do not have changes associated with an increased risk of heart disease, it is still possible that you develop heart disease. However for some rare diseases, people who have certain gene changes are guaranteed to develop the disease. When we are diagonosed out with certain genetic disease, are we suppose to disclose this result to our relatives? My answer is no.\\n\\n\\nOn one hand, we do not want this potential danger causing firghtenning affects in our families\\' later lives. When people around us know that we got certain disease, their altitudes will be easily changed, whether caring us too much or keeping away from us. And both are not what we want since most of us just want to live as normal people. Surrounded by such concerns, it is very likely that we are distracted to worry about these problems. It is a concern that will be with us during our whole life, because we will never know when the \\'\\'potential bomb\\'\\' will explode.\\n\\n\\nOn the other hand, if there are ways can help us to control or cure the disease, we can going through thses process from the scope of the whole family. For an example, if exercising is helpful for family potential disease, we can always look for more chances for the family to go exercise. And we keep track of all family members health conditions. At the same time, we are prepared to know when there are other members got this disease.\\n\\n\\nHere I want to share Forest\\'view on this issue. Although some people feel that an individual who is found to carry a dominant gene for Huntington\\'s disease has an ethical obligation to disclose that fact to his or her siblings, there currently is no legal requirement to do so. In fact, requiring someone to communicate his or her own genetic risk to family members who are therefore also at risk is considered by many to be ethically dubious.\"\\n\\n\\nNothing is absolute right or wrong. If certain disease genetic test is very accurate and it is unavoidable and necessary to get treatment and known by others, it is OK to disclose the result. Above all, life is more important than secret.\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFNMZpKHiPt-"
      },
      "source": [
        "`text`태그 내의 text정보만 추출하면 new line (\\n) 문자가 여러 존재합니다. 문자열 기준 가장 앞과 뒤에 있는 `\\n`은 `strip()`함수를 통해 제거 가능합니다. 또한 중간에 있는 `\\n\\n\\n`은 각 문단을 구분해주는 역할을 하므로, 해당 문자열을 기준으로 `split()`을 적용해 문단을 나누겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrJ9bwjEiDR3",
        "outputId": "1a73a29f-9c77-430b-e85b-64b83b17157e"
      },
      "source": [
        "paragraph_list = conllsoup.find('text').text.strip().split('\\n\\n\\n')\n",
        "paragraph_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Keeping the Secret of Genetic Testing',\n",
              " 'What is genetic risk? Genetic risk refers more to your chance of inheriting a disorder or disease. People get certain disease because of genetic changes. How much a genetic change tells us about your chance of developing a disorder is not always clear. If your genetic results indicate that you have gene changes associated with an increased risk of heart disease, it does not mean that you definitely will develop heart disease. The opposite is also true. If your genetic results show that you do not have changes associated with an increased risk of heart disease, it is still possible that you develop heart disease. However for some rare diseases, people who have certain gene changes are guaranteed to develop the disease. When we are diagonosed out with certain genetic disease, are we suppose to disclose this result to our relatives? My answer is no.',\n",
              " \"On one hand, we do not want this potential danger causing firghtenning affects in our families' later lives. When people around us know that we got certain disease, their altitudes will be easily changed, whether caring us too much or keeping away from us. And both are not what we want since most of us just want to live as normal people. Surrounded by such concerns, it is very likely that we are distracted to worry about these problems. It is a concern that will be with us during our whole life, because we will never know when the ''potential bomb'' will explode.\",\n",
              " 'On the other hand, if there are ways can help us to control or cure the disease, we can going through thses process from the scope of the whole family. For an example, if exercising is helpful for family potential disease, we can always look for more chances for the family to go exercise. And we keep track of all family members health conditions. At the same time, we are prepared to know when there are other members got this disease.',\n",
              " 'Here I want to share Forest\\'view on this issue. Although some people feel that an individual who is found to carry a dominant gene for Huntington\\'s disease has an ethical obligation to disclose that fact to his or her siblings, there currently is no legal requirement to do so. In fact, requiring someone to communicate his or her own genetic risk to family members who are therefore also at risk is considered by many to be ethically dubious.\"',\n",
              " 'Nothing is absolute right or wrong. If certain disease genetic test is very accurate and it is unavoidable and necessary to get treatment and known by others, it is OK to disclose the result. Above all, life is more important than secret.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nds1SfS3iloI"
      },
      "source": [
        "위와 같이 리스트 안에 각각의 문단을 요소로 입력하면, 인덱싱을 통해 원하는 문단에 쉽게 접근 가능합니다. 이제 `mistake`의 속성 정보를 활용해 문법 오류 위치를 확인해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFQx7vyRldvo",
        "outputId": "bec03ea9-cf37-4149-c806-fc9858ba6a09"
      },
      "source": [
        "print(conllsoup.find('mistake'))\n",
        "print('\\n')\n",
        "print('mistake:', paragraph_list[1][42:46])\n",
        "print('\\n')\n",
        "print(paragraph_list[1][:98])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<mistake end_off=\"46\" end_par=\"1\" start_off=\"42\" start_par=\"1\">\n",
            "<type>ArtOrDet</type>\n",
            "<correction></correction>\n",
            "</mistake>\n",
            "\n",
            "\n",
            "mistake: more\n",
            "\n",
            "\n",
            "What is genetic risk? Genetic risk refers more to your chance of inheriting a disorder or disease.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYgPLXjymP8G"
      },
      "source": [
        "`start_par`과 `end_par`이 1이므로, `paragraph_list`에서 1번째 위치하는 문단을 가지고 와서 `start_off`와 `end_off`에 나와있는 42과 46번째 사이의 단어를 추출합니다. `more`이 문법 오류가 있는 단어이고, 해당 단어를 제거해야 한다고 나와 있습니다. 전체 문장을 확인해보니 `more`이 없어야 올바른 문장이 되는 것을 확인할 수 있습니다. \n",
        "\n",
        "파이썬에서 string은 immutable합니다. 즉, 내용물을 수정할 수 없는 데이터 타입입니다. string을 수정하기 위해선 `slicing`방법을 사용해야 합니다. 문법 오류 단어가 존재하는 앞, 뒤 문장을 자른 후, 추후 올바른 단어와 병합을 하는 방식입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "NobI9zh0nVOd",
        "outputId": "60fa8971-b2b8-45c2-e08b-3570af1839c0"
      },
      "source": [
        "paragraph_list[1][:42] + '[CORRECTION]' + paragraph_list[1][46:98]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What is genetic risk? Genetic risk refers [CORRECTION] to your chance of inheriting a disorder or disease.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIyEfdZ0tTTA"
      },
      "source": [
        "위와 같이 전체 문단의 처음부터 `start_off`까지의 문자열과 `end_off`부터 마지막까지의 문자열 사이에 올바른 단어인 [CORRECTION]을 넣어주는 방법입니다. 실제 대체할 때는 [CORRECTION] 토큰 대신 올바른 단어를 입력해주면 됩니다. 98까지만 인덱싱한 이유는 문단 길이가 너무 길어서 출력 창 소비를 줄이기 위함입니다. \n",
        "\n",
        "위와 같은 기능을 하는 `edit_paragraph` 사용자 정의 함수를 정의하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poUCtXfWuPiu"
      },
      "source": [
        "def edit_paragraph(paragraph, start, end, correction):\n",
        "    return paragraph[:start] + correction + paragraph[end:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2UI8i4zuW9T"
      },
      "source": [
        "그 다음으로 필요한 기능은 인덱스를 업데이트 해주는 기능입니다. 모든 `mistake`들은 원본 데이터를 기준으로 문자열의 좌표 위치가 기록돼 있으므로, 단어를 하나씩 대체할 때마다 그 이후에 오는 단어의 좌표를 업데이트 해줄 필요 있습니다. 예를 들어 `I can do this all day`라는 예시 문장이 있을 때 아래와 같이 수정사항이 표시돼있다고 가정하겠습니다. \n",
        "\n",
        "- [2, 5, 'will']\n",
        "- [18, 21, 'night']\n",
        "\n",
        "즉 [2:5] 위치에 있는 단어를 'will'로 수정하고, [18:21] 위치에 있는 단어를 'day'로 수정한다는 뜻입니다. 앞서 정의한 `edit_paragraph()`함수를 활용한다면 아래와 같은 결과물이 나옵니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlhBOKuKnC5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d09046-cb16-4fa3-dd37-5edad0d37608"
      },
      "source": [
        "sample = 'i can do this all day'\n",
        "print(sample, '\\n')\n",
        "\n",
        "print('mistake #1:', sample[2:5])\n",
        "\n",
        "edit1 = edit_paragraph(sample, 2, 5, 'will')\n",
        "print(edit1, '\\n')\n",
        "\n",
        "print('mistake #2:', sample[18:21])\n",
        "\n",
        "edit2 = edit_paragraph(edit1, 18, 21, 'night')\n",
        "print(edit2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i can do this all day \n",
            "\n",
            "mistake #1: can\n",
            "i will do this all day \n",
            "\n",
            "mistake #2: day\n",
            "i will do this allnighty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5X0FkyPGShf"
      },
      "source": [
        "첫번째 오류 단어인 `can`은 올바르게 `will`로 대체가 됐습니다. 하지만 두번째 오류 단어인 `day`는 `night`으로 올바르게 대체가 되지 않았습니다. `can`이 `will`로 바뀌면서 `day`의 인덱스가 [18:21]에서 [19:22]로 변경 됐기 때문입니다. 이처럼 단어를 하나씩 바꿀 때마다 그 이후에 오는 단어들의 인덱스가 변경되기 때문에, 인덱스를 업데이트 해줄 필요가 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSCxGGe4GyGA",
        "outputId": "19c4f865-3141-4c60-b882-de215053545f"
      },
      "source": [
        "print('mistake #2:', sample[18:21])\n",
        "\n",
        "edit2 = edit_paragraph(edit1, 19, 22, 'night')\n",
        "print(edit2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mistake #2: day\n",
            "i will do this all night\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB8-L6HlHGO0"
      },
      "source": [
        "지금껏 확인한 내용을 모두 정리하면 아래와 같은 사용자 정의 함수를 만들 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovEmUbYClnZH"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def edit_paragraph(paragraph, start, end, correction):\n",
        "    return paragraph[:start] + correction + paragraph[end:]\n",
        "\n",
        "def update_index(paragraph, offset, corrections):\n",
        "    '''\n",
        "    paragraph: 원문\n",
        "    offset: 원본 위치정보\n",
        "    corrections: 수정해야 하는 단어\n",
        "    '''\n",
        "    raw_words = []\n",
        "    # 1. detect all the words at offset values in the paragraph / O(offset)\n",
        "    for of in offset:\n",
        "        raw_words.append(paragraph[of['start_off']:of['end_off']])\n",
        "\n",
        "    # 2. compare length change between the detected words and corrections (map is faster than list comprehension when it doesn't use lambda) / O(offset)\n",
        "    adjusted = np.array(list(map(len, corrections))) - np.array(list(map(len, raw_words)))\n",
        "\n",
        "    # cumulate adjusted values / O(offset)\n",
        "    for i in range(1, len(adjusted)):\n",
        "        adjusted[i] += adjusted[i-1]\n",
        "    \n",
        "    # 3. adjust the index sequentially / O(offset)\n",
        "    for i in range(1, len(offset)):\n",
        "        offset[i]['start_off'] += adjusted[i-1]\n",
        "        offset[i]['end_off'] += adjusted[i-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND22Lo1PHNiO"
      },
      "source": [
        "그리고 아래 알고리즘을 활용해 오류 단어들을 올바른 단어로 모두 수정해서 문법 오류가 없는 에세이를 생성하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4iwJd45kN5V"
      },
      "source": [
        "all_docs = conllsoup.find_all('doc')\n",
        "corrected_essays = []\n",
        "\n",
        "for doc in all_docs:\n",
        "    \n",
        "    # extract paragraphs\n",
        "    paragraph_lists = doc.find('text').text.strip().split('\\n\\n\\n')\n",
        "\n",
        "    # paragraph 별로 수정 진행\n",
        "    # make list that contains offset values\n",
        "\n",
        "    all_mistakes = doc.find_all('mistake')\n",
        "\n",
        "    for para_idx, para in enumerate(paragraph_lists):\n",
        "        edits = [mistake.attrs for mistake in all_mistakes if mistake.attrs['start_par'] == f'{para_idx}']\n",
        "\n",
        "        if len(edits) == 0:\n",
        "            continue\n",
        "        \n",
        "        edits = [{key: int(value) for key, value in edit.items()} for edit in edits]\n",
        "\n",
        "        # make list that contains correction information \n",
        "        corrections = [mistake.find('correction').text for mistake in all_mistakes if mistake.attrs['start_par'] == f'{para_idx}'] #start par과 end par은 항상 같은가?\n",
        "        \n",
        "        # reindexing\n",
        "        update_index(para, edits, corrections)\n",
        "\n",
        "        for edit_idx, edit in enumerate(edits):\n",
        "            para = edit_paragraph(para, int(edit['start_off']), int(edit['end_off']), corrections[edit_idx])\n",
        "\n",
        "        paragraph_lists[para_idx] = para\n",
        "\n",
        "    corrected_essays.append(' '.join(paragraph_lists))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHavPIrF0-ZQ",
        "outputId": "1d3b2637-b428-4946-d5ae-d9bce778a7bf"
      },
      "source": [
        "len(corrected_essays)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjV5HpiILkEW"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CwslqgvLfM2"
      },
      "source": [
        "sample_list = [1, 2, 3]\n",
        "file_name = \"corrected_essays.pkl\"\n",
        "\n",
        "open_file = open(file_name, \"wb\")\n",
        "pickle.dump(corrected_essays, open_file)\n",
        "open_file.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RXQm2w-MCFq"
      },
      "source": [
        "import pickle\n",
        "file_name = \"corrected_essays.pkl\"\n",
        "open_file = open(file_name, \"rb\")\n",
        "loaded_list = pickle.load(open_file)\n",
        "open_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unja3yXDwvSm"
      },
      "source": [
        "## 2.2 2019 BEA-2019 Shared Task Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkxi2Knx1lT6"
      },
      "source": [
        "BEA Workshop은 Association for Computational Linguistics special interest group for building educational applications (SIGEDU)에서 매년 운영하는 워크숍입니다. BEA Workshop은 Workshop on Innovative Use of NLP for Building Educational Applications의 약자이며, NLP를 교육 도메인에 적용하는 활용 사례들을 다루는 워크숍입니다. \n",
        "\n",
        "2019년에 개최된 BEA-2019 워크숍에서 Shared Task로 GEC 문제를 다뤘습니다. 해당 대회에서 새롭게 제공한 데이터셋은 Cambridge English Write & Improve (W&I) 데이터와 LOCNESS corpus 입니다.\n",
        "\n",
        "Write & Improve는 비영어권 학생들이 글쓰기 자료를 올려서 향상할 수 있는 방법을 피드백 받는 온라인 플랫폼입니다. 2014년도 부터 W&I 데이터 어노테이터 (Annotator)들이 제출물들의 문법 오류를 수기로 기록을 해왔기 때문에, 본 대회에서는 해당 데이터를 훈련용, 검증용, 시험용 데이터로 공개했습니다. \n",
        "\n",
        "그 외에도 LOCNESS corpus를 공개했습니다. LOCNESS는 영국과 미국의 원어민 학부생들이 작성한 약 400개의 에세이가 담긴 말뭉치입니다. 필터링 과정을 거쳐 총 100개의 에세이를 W&I 데이터 어노테이터들이 라벨링 해서 검증용, 시험용 데이터로 공개했습니다. 샘플 개수가 100개 밖에 되지 않아 별도로 훈련용 데이터로는 제공하지 않았습니다. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiOfE4G3Kl0y"
      },
      "source": [
        "### 2.2.1 W&I + LOCNESS 데이터 탐색"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4pHMJXI3_G"
      },
      "source": [
        "먼저 `wget`명령어를 활용해 [BEA 2019 Shared Task 홈페이지](https://www.cl.cam.ac.uk/research/nl/bea2019st/)로 부터 압축 파일을 다운로드해 와서 `bea19.tar.gz`로 저장합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr_eJ6vTDrNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d89ea0dc-1b1f-4a70-c1f1-a0eedbe67575"
      },
      "source": [
        "!wget -O 'bea19.tar.gz' https://www.cl.cam.ac.uk/research/nl/bea2019st/data/wi+locness_v2.1.bea19.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-08 10:56:11--  https://www.cl.cam.ac.uk/research/nl/bea2019st/data/wi+locness_v2.1.bea19.tar.gz\n",
            "Resolving www.cl.cam.ac.uk (www.cl.cam.ac.uk)... 128.232.0.20, 2a05:b400:110::80:14\n",
            "Connecting to www.cl.cam.ac.uk (www.cl.cam.ac.uk)|128.232.0.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6120469 (5.8M) [application/x-gzip]\n",
            "Saving to: ‘bea19.tar.gz’\n",
            "\n",
            "bea19.tar.gz        100%[===================>]   5.84M  8.78MB/s    in 0.7s    \n",
            "\n",
            "2021-04-08 10:56:13 (8.78 MB/s) - ‘bea19.tar.gz’ saved [6120469/6120469]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDmC75NXJPeo"
      },
      "source": [
        "정상적으로 파일이 불러왔다면 그림 2-3와 같이 `bea19.tar.gz`파일이 생성돼 있을 것입니다. 다음으로는 `tar`명령어를 활용해 압축을 해제하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LUgvxrIKCBh"
      },
      "source": [
        "!tar -xf bea19.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFA4O1IsJYzC"
      },
      "source": [
        "압축을 해제하면 그림 2-4와같이 폴더가 구성돼있습니다. 각 폴더가 의미하는 바는 다음과 같습니다. \n",
        "\n",
        "- `json`: json 형태의 W&I 와 LOCNESS 파일\n",
        "- `m2`: m2 형태의 W&I 와 LOCNESS 파일\n",
        "- `test`: 테스트 데이터\n",
        "\n",
        "W&I 파일은 CEFR (Common European Framework of Reference for Languages) 레벨에 따라 A, B, C등급으로 나눠져있습니다. A에서 C로 갈수록 높은 수준의 영어를 구사한다는 의미입니다. LOCNESS파일은 N으로 표시돼있습니다. \n",
        "\n",
        "문제 생성시 활용할 지문으로는 C등급 파일과 원어민이 작성한 LOCNESS 파일의 에세이를 사용하도록 하겠습니다. 우선 C등급 파일의 경로를 `path`변수에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQrQFraf2RtV"
      },
      "source": [
        "path = 'wi+locness/json/C.dev.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSkVrGiAbIvh"
      },
      "source": [
        "그 후 `open()`함수로 파일을 열고나서 내용물을 `readlines()`를 통해 읽어서 `data`변수에 저장합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhtK8Vl8avGS"
      },
      "source": [
        "with open(path) as f:\n",
        "  data = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50NdmDjzbRD1"
      },
      "source": [
        "먼저 데이터 타입을 확인합니다. 데이터 타입이 `list`이므로 인덱싱이 가능합니다. 첫번째 요소에 접근해서 확인해보면 다음과 같은 문자열이 들어가 있는 것을 확인할 수 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3nYYGNR2uPf",
        "outputId": "445ddd40-5113-4ed0-8ed3-a981e72afca5"
      },
      "source": [
        "print(type(data))\n",
        "\n",
        "print(type(data[0]))\n",
        "\n",
        "print(data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'str'>\n",
            "{\"edits\": [[0, [[89, 98, \"saw\"], [316, 316, \" for\"], [343, 343, \" for\"], [365, 365, \" a\"], [375, 375, \" the\"], [406, 406, \" a\"], [469, 471, \"of\"], [523, 527, \"know\"], [589, 594, \"chips\"]]]], \"userid\": \"24796\", \"text\": \"Dear Mrs. Ashby, \\n\\nYesterday I was in Green Pepper Cafe for a meal with colleagues and I have seen the advertisement for a job at weekends in your cafe. \\n\\nI am very interested in this work and believe that my employment background is appropriate for it. \\n\\nI am a Tourism student and I need to work at weekends to pay my studies. \\nI have worked one year in London as waiter in Hard Rock Cafe and 6 months as waiter also in Barcomi\\u2019s Cafe in Berlin. So I have experience in service, costumer care and working long hours. \\n\\nI Know how to prepare different kinds of food: sandwiches, fish and fries, hamburgers, Italian pasta, etc \\n\\nI am also very good at dealing with people, I have never had a complaint sheet!\\n\\nI have total availability at weekends and also in summer. \\n\\nI speak Spanish, English and German. \\n\\nPlease, find attached a copy of my CV, which expands on my experience and achievements. \\n\\nI am looking forward to talking with you about the possibility of working in this position. I am available to do an interview when it is convenient for you.\\n\\nThank you for your time and consideration. \\n\\n\\n\\nYours Sincerely, \\n\\n\\n\\nMar\\u00eda Luisa Castaneda del Acuna\\n\", \"cefr\": \"C2.ii\", \"id\": \"1-169309\"}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbi_BhsScNMT"
      },
      "source": [
        "문자열을 살펴보면 key값과 value값으로 나눠 저장돼있는 딕셔너리 형태인것을 확인할 수 있습니다. 해당 데이터를 용이하게 처리하기 위해 문자열을 딕셔너리로 변환하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M5G849Nl_Us"
      },
      "source": [
        "import json\n",
        "\n",
        "data = list(map(json.loads, data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvbjlc_0cjrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af14e016-5ed4-440a-a38f-fc3dcc76a4c4"
      },
      "source": [
        "print(type(data[0]))\n",
        "\n",
        "print(data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "{'edits': [[0, [[89, 98, 'saw'], [316, 316, ' for'], [343, 343, ' for'], [365, 365, ' a'], [375, 375, ' the'], [406, 406, ' a'], [469, 471, 'of'], [523, 527, 'know'], [589, 594, 'chips']]]], 'userid': '24796', 'text': 'Dear Mrs. Ashby, \\n\\nYesterday I was in Green Pepper Cafe for a meal with colleagues and I have seen the advertisement for a job at weekends in your cafe. \\n\\nI am very interested in this work and believe that my employment background is appropriate for it. \\n\\nI am a Tourism student and I need to work at weekends to pay my studies. \\nI have worked one year in London as waiter in Hard Rock Cafe and 6 months as waiter also in Barcomi’s Cafe in Berlin. So I have experience in service, costumer care and working long hours. \\n\\nI Know how to prepare different kinds of food: sandwiches, fish and fries, hamburgers, Italian pasta, etc \\n\\nI am also very good at dealing with people, I have never had a complaint sheet!\\n\\nI have total availability at weekends and also in summer. \\n\\nI speak Spanish, English and German. \\n\\nPlease, find attached a copy of my CV, which expands on my experience and achievements. \\n\\nI am looking forward to talking with you about the possibility of working in this position. I am available to do an interview when it is convenient for you.\\n\\nThank you for your time and consideration. \\n\\n\\n\\nYours Sincerely, \\n\\n\\n\\nMaría Luisa Castaneda del Acuna\\n', 'cefr': 'C2.ii', 'id': '1-169309'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t2rclZvcrM_"
      },
      "source": [
        "문자열이 모두 딕셔너리로 변환됐습니다. 다음으로는 딕셔너리의 키를 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PisubQV7aLAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75daf118-abc2-4878-cd34-5415953ad03b"
      },
      "source": [
        "data[0].keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['edits', 'userid', 'text', 'cefr', 'id'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8AmxSWoc0lL"
      },
      "source": [
        "각 키의 의미는 다음과 같습니다. \n",
        "\n",
        "\n",
        "- `cefr`: text의 CEFR 레벨\n",
        "- `edits`: 문법 오류 위치와 올바른 단어\n",
        "- `id`: 에세이 고유번호\n",
        "- `text`: 에세이 원본\n",
        "- `userid`: 사용자 고유번호"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieenQuofhtN9"
      },
      "source": [
        "BEA 2019 데이터도 2014 CoNLL 데이터 처럼 문법 오류의 위치가 인덱스로 기록돼있고, 어떤 단어로 고쳐야하는지 라벨링이 돼있습니다. `edits` 키를 확인해 어떻게 기록 돼있는지 확인해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zja6cBc-h7lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc1e5f7-d892-4f24-8eb7-c943a025c23e"
      },
      "source": [
        "data[0]['edits']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0,\n",
              "  [[89, 98, 'saw'],\n",
              "   [310, 310, ' for'],\n",
              "   [341, 341, ' for'],\n",
              "   [367, 367, ' a'],\n",
              "   [379, 379, ' the'],\n",
              "   [414, 414, ' a'],\n",
              "   [479, 481, 'of'],\n",
              "   [533, 537, 'know'],\n",
              "   [599, 604, 'chips']]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq0K9qChiAJJ"
      },
      "source": [
        "가장 첫번째 나오는 숫자 0은 어노테이터의 고유번호를 뜻합니다. 그 다음으로 나오는 정보들이 오류의 시작위치, 오류가 끝나는 위치, 그리고 올바른 단어를 의미합니다. 즉, 2014 CoNLL 전처리 시 활용한 함수들을 조금 수정하여 그대로 전처리에 활용가능합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ry6xU1pQ5we"
      },
      "source": [
        "### 2.2.2 W&I + LOCNESS 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0nRiVgpmbCx"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def edit_paragraph(paragraph, start, end, correction):\n",
        "    return paragraph[:start] + correction + paragraph[end:]\n",
        "\n",
        "def update_index_BEA(paragraph, edits):\n",
        "    '''\n",
        "    paragraph: 원문\n",
        "    edits: edits from BEA_2019\n",
        "    '''\n",
        "    raw_words = []\n",
        "    corrections = []\n",
        "\n",
        "    # 1. detect all the words at offset values in the paragraph / O(offset)\n",
        "    for edit in edits:\n",
        "        raw_words.append(paragraph[edit[0]:edit[1]])\n",
        "        # make corrections\n",
        "        corrections.append(edit[2])\n",
        "\n",
        "    # 2. compare length change between the detected words and corrections (map is faster than list comprehension when it doesn't use lambda) / O(offset)\n",
        "    adjusted = np.array(list(map(len, corrections))) - np.array(list(map(len, raw_words)))\n",
        "\n",
        "    # cumulate adjusted values / O(offset)\n",
        "    for i in range(1, len(adjusted)):\n",
        "        adjusted[i] += adjusted[i-1]\n",
        "    \n",
        "    # 3. adjust the index sequentially / O(offset)\n",
        "    for i in range(1, len(edits)):\n",
        "        edits[i][0] += adjusted[i-1]\n",
        "        edits[i][1] += adjusted[i-1]\n",
        "\n",
        "    return corrections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WiYVWX0ielx"
      },
      "source": [
        "BEA 2019에는 None Type이 존재하기도 하므로, 해당 샘플은 예외 처리 하는 로직이 필요합니다. 예를 들어 8번재 문서를 확인해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "3uB1NK1Pax-l",
        "outputId": "1ea94b2c-7f56-4d62-a6a3-fe9d24e693a2"
      },
      "source": [
        "edits = data[8]['edits'][0][1]\n",
        "\n",
        "corrections = update_index_BEA(data[8]['text'], edits)\n",
        "\n",
        "edits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-65b5b20092fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0medits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcorrections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_index_BEA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0medits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-f8f89874637d>\u001b[0m in \u001b[0;36mupdate_index_BEA\u001b[0;34m(paragraph, edits)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# 2. compare length change between the detected words and corrections (map is faster than list comprehension when it doesn't use lambda) / O(offset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0madjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# cumulate adjusted values / O(offset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC9nZoKZjOdp"
      },
      "source": [
        "단어간 길이를 비교할 때 None Type이 있으면 에러가 나므로, None Type은 모두 제거하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQe0Ya-GjIOL"
      },
      "source": [
        "[edit for edit in edits if edit[2] != None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Lcn23S-2YscR",
        "outputId": "765cf6db-7bd2-40ae-da63-45284bb43deb"
      },
      "source": [
        "' '.join(para.split('\\n\\n\\t'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"How does Voltaire tackle the question of philosophical optimism in 'Candide'? Philosophical optimism -l'optimisme- is the philosophy that everything and any occurrence is for some good. Voltaire sets out in Candide to criticise this philosophy. In Candide, the representative of this philosophy is Pangloss, the philosopher employed at Thunder-der-Troncks. The whole book is a criticism of l'optimisme. For example, when Candide is forced to join the Bulgar army he is beaten almost to death, but Candide does not concern himself because he know it is for his own good - in fact, later in the book he uses his training to become a soldier. Although this would seem to be good, it is not. Because of his training, he kills two men, a Jew and an Archbishop with no hesitation and then proceeds to kill his sweetheart's brother. Voltaire shows his dislike of l'optimisme when Pangloss, Candide and James are caught in a bad storm at sea in which James is drowned and there are only three survivors; Candide, Pangloss and a sailor. The storm was caused by an earthquake which destroys the city to which Candide was sailing. On arrival they see starvation and death. Candide is obviously horrified, especially when the sailor begins pillaging the city. Candide looks to Pangloss for an answer, but Pangloss can only tell him that some good will come of it. Candide, although remaining true to the ideals of optimism, always appears to be sceptical of it. This is no more true than when he arrives in the new world, South America, and has to leave his darling Cunégonde with the Commissioner of the province. Candide cannot see what possible good can come of this, especially as the reason that he was in America was due to him killing the Jew and Archbishop because they were Cunégonde's lovers. Throughout the book, we begin to see how Candide is gradually led away from l'optimisme or, perhaps more importantly, how l'optimisme is shown to be the philosophy of despair. The constant belief that good can come from bad is not actually inspiring but leads to a constant flow of disasters. Candide's life, in the book, appears to show this. He is thrown out of Thunder-den-Tronck because he embraces Cunégonde, he is duped into the army, he is caught in an earthquake, he is almost killed as part of an auto-da-fé, he kills three churchmen, he is almost eaten, he finds Eldorado but leaves - the list continues. Candide's life is governed by his belief that good will prevail. Eventually, of course, he does marry Cunégonde, but she is not the beautiful young flower that he once loved. She has become ugly and grows worse by the day. This illustrates emphatically the folly of l'optimisme. Candide has travelled the world in search of Cunégonde, with the hope that he will marry he. Despite all the trouble which he has gone through, of course, in the end he does get Cunégonde but at the price of her looks and personality. Voltaire, in Candide, shows how the philosophy of Optimism is one of despair, not hope.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGgnO7kvh_LT"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBvg38QqfFsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1f879d-cacb-4712-b852-f779fb9cfad0"
      },
      "source": [
        "corrected_essays = []\n",
        "\n",
        "for doc in tqdm(data):\n",
        "    \n",
        "    # extract paragraphs\n",
        "    essay = doc['text']\n",
        "\n",
        "    # paragraph 별로 수정 진행\n",
        "    # make list that contains offset values\n",
        "\n",
        "    edits = doc['edits'][0][1]\n",
        "    edits = [edit for edit in edits if edit[2] != None] # NoneType 제거\n",
        "    corrections = update_index_BEA(essay, edits)    \n",
        "\n",
        "    for edit_idx, edit in enumerate(edits):\n",
        "        essay = edit_paragraph(essay, edit[0], edit[1], corrections[edit_idx])\n",
        "\n",
        "    corrected_essays.append(' '.join(essay.split('\\n\\n\\t')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70/70 [00:00<00:00, 7334.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f0nGkJogdJE"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXptjlCXgU0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "0c0a1f11-6ea5-4b49-9151-cb5e54ea0dae"
      },
      "source": [
        "re.sub('\\n', '', corrected_essays[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dear Mrs. Ashby, Yesterday I was in Green Pepper Cafe for a meal with colleagues and I saw the advertisement for a job at weekends in your cafe. I am very interested in this work and believe that my employment background is appropriate for it. I am a Tourism student and I need to work at weekends to pay for my studies. I have worked for one year in London as a waiter in the Hard Rock Cafe and 6 months as a waiter also in Barcomi’s Cafe in Berlin. So I have experience of service, costumer care and working long hours. I know how to prepare different kinds of food: sandwiches, fish and chips, hamburgers, Italian pasta, etc I am also very good at dealing with people, I have never had a complaint sheet!I have total availability at weekends and also in summer. I speak Spanish, English and German. Please, find attached a copy of my CV, which expands on my experience and achievements. I am looking forward to talking with you about the possibility of working in this position. I am available to do an interview when it is convenient for you.Thank you for your time and consideration. Yours Sincerely, María Luisa Castaneda del Acuna'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRpbVPuJX40s"
      },
      "source": [
        "## 참고문헌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmQiQ7lyX2Ul"
      },
      "source": [
        "[1] Ng, H. T., Wu, S. M., Briscoe, T., Hadiwinoto, C., Susanto, R. H., & Bryant, C. (2014). The CoNLL-2014 Shared Task on Grammatical Error Correction. Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task, 1–14. https://doi.org/10.3115/v1/W14-1701\n",
        "\n",
        "[2] Bryant, C., Felice, M., Andersen, I. E., & Briscoe, T. (2019). The BEA-2019 Shared Task on Grammatical Error Correction. Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, 52–75. https://doi.org/10.18653/v1/w19-4406\n",
        "\n",
        "[3] https://www.differencebetween.com/difference-between-html-and-vs-sgml/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Zxd0gcX4Da"
      },
      "source": [
        "[\"essay1\", \"essay2\", \"essay3\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm5KeukgoDPD"
      },
      "source": [
        "ch6. reference "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vqOcBhSaWXE"
      },
      "source": [
        "!pip install benepar==0.1.2\n",
        "!pip install summa\n",
        "!pip install nltk==3.4.5\n",
        "!pip install spacy==2.1.0\n",
        "!python3 -m spacy download en\n",
        "!pip install scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlupgRFFbvF2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "outputId": "5ebead3e-5c3c-4d1b-830b-1d04fa09972a"
      },
      "source": [
        "!pip install tensorflow==1.14.0 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 44.1MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 48.4MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (54.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7trEMGTNa2dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5857b113-7908-450c-86c4-8b51627e3875"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "from summa.summarizer import summarize\n",
        "import benepar\n",
        "import string\n",
        "import nltk\n",
        "from nltk import tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "from random import shuffle\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "#this package is required for the summa summarizer\n",
        "nltk.download('punkt')\n",
        "benepar.download('benepar_en2')\n",
        "benepar_parser = benepar.Parser(\"benepar_en2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package benepar_en2 to /root/nltk_data...\n",
            "[nltk_data]   Package benepar_en2 is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kr-GAfqbjLN"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adLwq3EkbIVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f9a158-3c9c-4f55-ec27-0195354a7a00"
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "def preprocess(sentences):\n",
        "    output = []\n",
        "    for sent in sentences:\n",
        "        single_quotes_present = len(re.findall(r\"['][\\w\\s.:;,!?\\\\-]+[']\",sent))>0\n",
        "        double_quotes_present = len(re.findall(r'[\"][\\w\\s.:;,!?\\\\-]+[\"]',sent))>0\n",
        "        question_present = \"?\" in sent\n",
        "        if single_quotes_present or double_quotes_present or question_present :\n",
        "            continue\n",
        "        else:\n",
        "            output.append(sent.strip(punctuation))\n",
        "    return output\n",
        "        \n",
        "        \n",
        "def get_candidate_sents(resolved_text, ratio=0.3):\n",
        "    candidate_sents = summarize(resolved_text, ratio=ratio)\n",
        "    candidate_sents_list = tokenize.sent_tokenize(candidate_sents)\n",
        "    candidate_sents_list = [re.split(r'[:;]+',x)[0] for x in candidate_sents_list ]\n",
        "    # Remove very short sentences less than 30 characters and long sentences greater than 150 characters\n",
        "    filtered_list_short_sentences = [sent for sent in candidate_sents_list if len(sent)>30 and len(sent)<150]\n",
        "    return filtered_list_short_sentences\n",
        "\n",
        "cand_sents = get_candidate_sents(sentences[0])\n",
        "filter_quotes_and_questions = preprocess(cand_sents)\n",
        "for each_sentence in filter_quotes_and_questions:\n",
        "    print (each_sentence)\n",
        "    print (\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The convenience and high efficiency of using electronic products is being noticed by people worldwide\n",
            "\n",
            "\n",
            "In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to track people\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWTCNsEbMGog",
        "outputId": "8bd4a0e7-085d-436b-94ce-45b5cef778da"
      },
      "source": [
        "\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "    \n",
        "def get_flattened(t):\n",
        "    sent_str_final = None\n",
        "    if t is not None:\n",
        "        sent_str = [\" \".join(x.leaves()) for x in list(t)]\n",
        "        sent_str_final = [\" \".join(sent_str)]\n",
        "        sent_str_final = sent_str_final[0]\n",
        "    return sent_str_final\n",
        "    \n",
        "\n",
        "def get_termination_portion(main_string,sub_string):\n",
        "    combined_sub_string = sub_string.replace(\" \",\"\")\n",
        "    main_string_list = main_string.split()\n",
        "    last_index = len(main_string_list)\n",
        "    for i in range(last_index):\n",
        "        check_string_list = main_string_list[i:]\n",
        "        check_string = \"\".join(check_string_list)\n",
        "        check_string = check_string.replace(\" \",\"\")\n",
        "        if check_string == combined_sub_string:\n",
        "            return \" \".join(main_string_list[:i])\n",
        "                     \n",
        "    return None\n",
        "    \n",
        "def get_right_most_VP_or_NP(parse_tree,last_NP = None,last_VP = None):\n",
        "    if len(parse_tree.leaves()) == 1:\n",
        "        return get_flattened(last_NP),get_flattened(last_VP)\n",
        "    last_subtree = parse_tree[-1]\n",
        "    if last_subtree.label() == \"NP\":\n",
        "        last_NP = last_subtree\n",
        "    elif last_subtree.label() == \"VP\":\n",
        "        last_VP = last_subtree\n",
        "    \n",
        "    return get_right_most_VP_or_NP(last_subtree,last_NP,last_VP)\n",
        "\n",
        "\n",
        "def get_sentence_completions(key_sentences):\n",
        "    sentence_completion_dict = {}\n",
        "    for individual_sentence in filter_quotes_and_questions:\n",
        "        sentence = individual_sentence.rstrip('?:!.,;')\n",
        "        tree = benepar_parser.parse(sentence)\n",
        "        last_nounphrase, last_verbphrase =  get_right_most_VP_or_NP(tree)\n",
        "        phrases= []\n",
        "        if last_verbphrase is not None:\n",
        "            verbphrase_string = get_termination_portion(sentence,last_verbphrase)\n",
        "            phrases.append(verbphrase_string)\n",
        "        if last_nounphrase is not None:\n",
        "            nounphrase_string = get_termination_portion(sentence,last_nounphrase)\n",
        "            phrases.append(nounphrase_string)\n",
        "\n",
        "        longest_phrase =  sorted(phrases, key=len,reverse= True)\n",
        "        if len(longest_phrase) == 2:\n",
        "            first_sent_len = len(longest_phrase[0].split())\n",
        "            second_sentence_len = len(longest_phrase[1].split())\n",
        "            if (first_sent_len - second_sentence_len) > 4:\n",
        "                del longest_phrase[1]\n",
        "                \n",
        "        if len(longest_phrase)>0:\n",
        "            sentence_completion_dict[sentence]=longest_phrase\n",
        "    return sentence_completion_dict\n",
        "\n",
        "\n",
        "\n",
        "sent_completion_dict = get_sentence_completions(filter_quotes_and_questions)\n",
        "\n",
        "print (sent_completion_dict)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'The convenience and high efficiency of using electronic products is being noticed by people worldwide': ['The convenience and high efficiency of using electronic products is being noticed by', 'The convenience and high efficiency of using electronic products is being'], 'In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to track people': ['In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to track', 'In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JZsvzhbcYoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653cc08a-a12c-4104-a2e3-5c9ea56fdc0f"
      },
      "source": [
        "sent_completion_dict['The convenience and high efficiency of using electronic products is being noticed by people worldwide']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The convenience and high efficiency of using electronic products is being noticed by',\n",
              " 'The convenience and high efficiency of using electronic products is being']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfhP8w-SclKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a5abb5-e96b-4f70-b839-de0c5fabdd61"
      },
      "source": [
        "sent_completion_dict['In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to track people']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to track',\n",
              " 'In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJdj2MFlczpP"
      },
      "source": [
        "\n",
        "!pip install sentence-transformers==0.2.5.1\n",
        "!pip install transformers==2.6.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqtrQrCtcrpU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "55876bba14a74ed08ab3cca918d0d3e2",
            "4ad8bfb8e86d48dfb3a6ba6eedbe87a9",
            "b25aa26f95d548a9a0170856ad310ca5",
            "1fb68017fd424709a3a6bb18743c2f45",
            "38528bb95ef84777b65c3a8155e4f486",
            "2a9fa1bf24fe4948aafa169ae9085a21",
            "c02d231a0bbe42438b930a4b85c6a5e1",
            "0356e679e3b24a0daea1403a4db94b72",
            "ce3e610f340e4126bd536414d52a9430",
            "6eba1f126b2448c49481db35492f0056",
            "a1132e8a445d4b9aac1f1d51e4ef27dd",
            "5798cf012644463c9055713b24332543",
            "8ba165b274fe4640a567b112366afe04",
            "efe0525b071d4ab3a4fe5d51492e75df",
            "1a28b24a6f754881b7aa66c24c047ac9",
            "027532b86b9948cb8472270372957e8d",
            "a9f194240d28445b919af67f69b9239f",
            "aa65f12233ba40578367b5c416a98b65",
            "7b54e149c6154531b4a030a64b4fc3a8",
            "35845085ce11409fb05b80666798a13d",
            "4a62d98359554d24b7615d9c3622a9ab",
            "03e28307af124cfda60f94fea6f61f88",
            "471877dd6db14d5da9b304b757f7bf2a",
            "99b84a050a9b4ffdb822c16fecadc1dd",
            "08d79dc449154f6189ca8f48296221e8",
            "aec04ba2a9ac48d4a3d8b2a3514c79f4",
            "e9fe5dd092b64274985f5e6f23fbf05f",
            "9a36e27a9e3d4693a0e503d24eb349e1",
            "169a2b164d89432197cd4374c87dda27",
            "1a4cbd4c9b844ddda63239731b260384",
            "161df82401824cf497fa30bc1c8f96e9",
            "1dd5715c429f43ebb2e1056df0449498"
          ]
        },
        "outputId": "74a23b66-3178-4422-fc73-34e7169ab7c1"
      },
      "source": [
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\",pad_token_id=tokenizer.eos_token_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55876bba14a74ed08ab3cca918d0d3e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce3e610f340e4126bd536414d52a9430",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9f194240d28445b919af67f69b9239f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08d79dc449154f6189ca8f48296221e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DrM_1Mtcvwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653cc04c-da39-46f9-8a1b-af6bb0d789d6"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "# Load the BERT model. Various models trained on Natural Language Inference (NLI) https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/nli-models.md and \n",
        "# Semantic Textual Similarity are available https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/sts-models.md\n",
        "model_BERT = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:32<00:00, 12.5MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwXJ1l1DdTzu"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFkO3wx2cvZk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "30cfb7f4-00ac-4d76-9c50-41ec02787d66"
      },
      "source": [
        "from nltk import tokenize\n",
        "import scipy\n",
        "torch.manual_seed(2020)\n",
        "\n",
        "\n",
        "def sort_by_similarity(original_sentence,generated_sentences_list):\n",
        "    # Each sentence is encoded as a 1-D vector with 768 columns\n",
        "    sentence_embeddings = model_BERT.encode(generated_sentences_list)\n",
        "\n",
        "    queries = [original_sentence]\n",
        "    query_embeddings = model_BERT.encode(queries)\n",
        "    # Find the top sentences of the corpus for each query sentence based on cosine similarity\n",
        "    number_top_matches = len(generated_sentences_list)\n",
        "\n",
        "    dissimilar_sentences = []\n",
        "\n",
        "    for query, query_embedding in zip(queries, query_embeddings):\n",
        "        distances = scipy.spatial.distance.cdist([query_embedding], sentence_embeddings, \"cosine\")[0]\n",
        "\n",
        "        results = zip(range(len(distances)), distances)\n",
        "        results = sorted(results, key=lambda x: x[1])\n",
        "\n",
        "\n",
        "        for idx, distance in reversed(results[0:number_top_matches]):\n",
        "            score = 1-distance\n",
        "            if score < 0.9:\n",
        "                dissimilar_sentences.append(generated_sentences_list[idx].strip())\n",
        "           \n",
        "    sorted_dissimilar_sentences = sorted(dissimilar_sentences, key=len)\n",
        "    \n",
        "    return sorted_dissimilar_sentences[:3]\n",
        "    \n",
        "\n",
        "def generate_sentences(partial_sentence,full_sentence):\n",
        "    input_ids = torch.tensor([tokenizer.encode(partial_sentence)])\n",
        "    maximum_length = len(partial_sentence.split())+80\n",
        "\n",
        "    # Actiavte top_k sampling and top_p sampling with only from 90% most likely words\n",
        "    sample_outputs = model.generate(\n",
        "        input_ids, \n",
        "        do_sample=True, \n",
        "        max_length=maximum_length, \n",
        "        top_p=0.90, # 0.85 \n",
        "        top_k=50,   #0.30\n",
        "        repetition_penalty  = 10.0,\n",
        "        num_return_sequences=10\n",
        "    )\n",
        "    generated_sentences=[]\n",
        "    for i, sample_output in enumerate(sample_outputs):\n",
        "        decoded_sentences = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "        decoded_sentences_list = tokenize.sent_tokenize(decoded_sentences)\n",
        "        generated_sentences.append(decoded_sentences_list[0])\n",
        "        \n",
        "    top_3_sentences = sort_by_similarity(full_sentence,generated_sentences)\n",
        "    \n",
        "    return top_3_sentences\n",
        "\n",
        "index = 1\n",
        "choice_list = [\"a)\",\"b)\",\"c)\",\"d)\",\"e)\",\"f)\"]\n",
        "for key_sentence in sent_completion_dict:\n",
        "    partial_sentences = sent_completion_dict[key_sentence]\n",
        "    false_sentences =[]\n",
        "    print_string = \"**%s) True Sentence (from the story) :**\"%(str(index))\n",
        "    printmd(print_string)\n",
        "    print (\"  \",key_sentence)\n",
        "    for partial_sent in partial_sentences:\n",
        "        false_sents = generate_sentences(partial_sent,key_sentence)\n",
        "        false_sentences.extend(false_sents)\n",
        "    printmd(\"  **False Sentences (GPT-2 Generated)**\")\n",
        "    for ind,false_sent in enumerate(false_sentences):\n",
        "        print_string_choices = \"**%s** %s\"%(choice_list[ind],false_sent)\n",
        "        printmd(print_string_choices)\n",
        "    index = index+1\n",
        "    \n",
        "    print (\"\\n\\n\")\n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**1) True Sentence (from the story) :**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "   The convenience and high efficiency of using electronic products is being noticed by people worldwide\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "  **False Sentences (GPT-2 Generated)**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**a)** The convenience and high efficiency of using electronic products is being noticed by more than 20 million consumers.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**b)** The convenience and high efficiency of using electronic products is being noticed by the general public, but this has not been recognized at a rapid pace.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**c)** The convenience and high efficiency of using electronic products is being noticed by many companies, for example from the consumer electronics retailer Samsung.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**d)** The convenience and high efficiency of using electronic products is being promoted by new devices.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**e)** The convenience and high efficiency of using electronic products is being taken to great effect,\" he added.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**f)** The convenience and high efficiency of using electronic products is being tested in laboratories across the world, including North America.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**2) True Sentence (from the story) :**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "   In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to track people\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "  **False Sentences (GPT-2 Generated)**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**a)** In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to track people and companies from day one in your society by the government.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**b)** In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to track individuals who do something in the privacy of their own homes instead rather than at work.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**c)** In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to track every location of someone who has paid the bill and is suspected by law enforcement agencies.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**d)** In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to keep track of what is going on inside our homes and businesses.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**e)** In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to identify individuals from the United States and other places then there are good reasons for using it.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**f)** In this essay, I will discuss that if surveillance technology such as RFID (radio-frequency identification) should be used or not to locate terrorist suspects using search warrants and/or law enforcement agencies it is only because of a need for effective monitoring.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf6cY7Wdcru-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "IR1SG59VMNb7",
        "outputId": "ddd33e09-5fa8-4aae-bbc3-bbe5bddd8ba8"
      },
      "source": [
        "sentences[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nRisks can be analyzed if there is a record of what was happened in the past. In late nineteenth century, there was a severe air crash happening at Miami international airport. The air cargo of the Valujet plane was on fire after the plane had taken off. Sooner or later, the electric systems were short circuited as a result that the airplane was out of control and nose diving to the ground with extremely high speed. All passengers and pilots were died. After finding and analyzing the black box of the Valujet after the incidence, police investigators found out reasons for causing this severe incidence. Surveillance technology can be used to detect very risky events and prevent its happening in the future, hence to save more lives. In addition, if surveillance technology is even better developed, it can be used to detect the problem before the real accidence has happened.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}
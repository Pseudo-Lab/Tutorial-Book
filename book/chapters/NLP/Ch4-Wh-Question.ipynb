{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch4-WH-Question copy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.10 64-bit ('WH': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10"
    },
    "accelerator": "GPU",
    "metadata": {
      "interpreter": {
        "hash": "08587b300ccbee895bd2ebc66f7ed19be4bbf7cde96cda90a3c96bc024fb86b1"
      }
    },
    "interpreter": {
      "hash": "08587b300ccbee895bd2ebc66f7ed19be4bbf7cde96cda90a3c96bc024fb86b1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8L_IPi5i8jA"
      },
      "source": [
        "# 4. Wh- Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAPyeQBSD5ht"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Pseudo-Lab/Tutorial-Book/blob/master/book/chapters/NLP/Ch4-Wh-Question.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_DuuDzneSzF"
      },
      "source": [
        "3장에서는 각 지문에 대한 True/False 문제를 생성해보았습니다. 이번 4장에서는 T5모델과 BERT모델로 Wh- 문제를 생성해보겠습니다. Cambridge Dictionary에 의하면 [Wh- 문제](https://dictionary.cambridge.org/ko/%EC%82%AC%EC%A0%84/%EC%98%81%EC%96%B4/wh-question)는 what, when, where, who, whom, which, whose, why, how로 시작하는 문제라고 정의되어 있습니다. 이번장에서는 이러한 Wh- 문제를 다지선다(Multi-Choice)로 생성해 볼 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hwnXWlHeSzF"
      },
      "source": [
        "4.1절에서는 모델의 입력값으로 사용할 에세이 데이터를 불러오고 4.2절에서는 정답 단어를 추출하는 함수를 만들어 보겠습니다. 4.3절에서는 Wh- 문제를 생성하는 클래스, 4.4절에서는 문제를 평가하는 클래스, 그리고 4.5절에서는 오답을 생성하는 클래스를 정의하도록 하겠습니다. 마지막으로 4.6절에서는 정의한 클래스들을 사용하여 실제 에세이 지문에서 Wh- 문제를 생성해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhpFpEoEeSzF"
      },
      "source": [
        "## 4.1 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j4z5yuOeSzG"
      },
      "source": [
        "문제 생성에 앞서 2장에서 저장한 데이터셋을 불러오도록 하겠습니다. 이 데이터셋은 전처리를 통해 올바른 표현으로 수정하여 저장해둔 데이터셋입니다. 2장에서 직접 저장한 파일을 불러오거나, 혹은 가짜연구소 깃허브에 저장된 파일을 불러와 사용할 수 있습니다. `CoNLL+BEA_corrected_essays.pkl` 파일 안에는 총 170개의 지문이 존재하며, 이 데이터는 Wh- 문제를 만들 지문으로 사용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKZhhDjyeSzG",
        "outputId": "ccbf782f-9346-41b4-d8d3-2f1203345ca1"
      },
      "source": [
        "!git clone https://github.com/Pseudo-Lab/Tutorial-Book-Utils\n",
        "!python Tutorial-Book-Utils/PL_data_loader.py --data NLP-QG"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Tutorial-Book-Utils'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 30 (delta 9), reused 18 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (30/30), done.\n",
            "CoNLL+BEA_corrected_essays.pkl is done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bev08YLeSzH"
      },
      "source": [
        "import pickle\n",
        "file_name = \"CoNLL+BEA_corrected_essays.pkl\"\n",
        "open_file = open(file_name, \"rb\")\n",
        "data = pickle.load(open_file)\n",
        "open_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVOFtICbeSzH",
        "outputId": "080e7c32-7f1e-4684-be23-441a4d95aa67"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pV7I_QgeSzI"
      },
      "source": [
        "첫 번째 지문을 예시로 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CpkDQuEeSzI",
        "outputId": "03b51ba2-e202-4f2b-9144-41f7963ed2f6"
      },
      "source": [
        "print(data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keeping the Secret of Genetic Testing What is genetic risk? Genetic risk refers  to your chance of inheriting a disorder or disease. People get certain diseases because of genetic changes. How much a genetic change tells us about your chance of developing a disorder is not always clear. If your genetic results indicate that you have gene changes associated with an increased risk of heart disease, it does not mean that you definitely will develop heart disease. The opposite is also true. If your genetic results show that you do not have changes associated with an increased risk of heart disease, it is still possible that you develop heart disease. However, for some rare diseases, people who have certain gene changes are guaranteed to develop the disease. When we are diagnosed with certain genetic diseases, are we suppose to disclose this result to our relatives? My answer is no. On one hand, we do not want this potential danger havingfrightening effects in our families' later lives. When people around us know that we have certain diseases, their attitude will easily change, whether caring for us too much or keeping away from us. And both are not what we want since most of us just want to live as normal people. Surrounded by such concerns, it is very likely that we are distracted and worry about these problems. It is a concern that will be with us during our whole life, because we  never know when the ''potential bomb'' will explode. On the other hand, if there are ways that can help us to control or cure the disease, we can go through these processes from the scope of the whole family. For  example, if exercising is helpful reducing family potential disease, we can always look for more chances for the family to do exerciseso we keep track of all family members health conditions. At the same time, we are prepared to know when there are other members who have got this disease. Here I want to share Forests'sview on this issue. Although some people feel that an individual who is found to carry a dominant gene for Huntington's disease has an ethical obligation to disclose that fact to his or her siblings, there currently is no legal requirement to do so. In fact, requiring someone to communicate his or her own genetic risk to family members who are therefore also at risk is considered by many to be ethically dubious.\" Nothing is absolutely right or wrong. If a certain  genetic test is very accurate and it is unavoidable and necessary to get treatment and tell  others, it is OK to disclose the result. Above all, life is more important than secrets.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5XtlirVeSzJ"
      },
      "source": [
        "함수를 정의하기 전에 4장에서 사용할 패키지들을 import 해보겠습니다. 각 환경에 따라 패키지가 없을 수 있으니 확인하시고 설치하시기 바랍니다. (Colab 환경에서는 `benepar` 패키지가 없어 아래 코드를 통해 설치해줍니다.)\n",
        "\n",
        "`benepar`와 `nltk`는 텍스트 파싱과 토크나이징에 사용할 수 있는 패키지입니다. 또한 `pandas`는 기본적인 데이터 프레임을 위한 패키지이고, `numpy`는 수치연산에 사용하는 패키지입니다. 그리고 `torch`는 모델 구축 프레임워크이고, 다양한 토큰화 기법과 모델들이 내장되어 있는 `transformers` 패키지도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "624imvmkgB7j"
      },
      "source": [
        "!pip install -q benepar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2IcmXrVh5PN",
        "outputId": "c1a441e0-41a9-423e-c0d2-524d1b868408"
      },
      "source": [
        "import benepar\n",
        "benepar.download('benepar_en3')\n",
        "benepar_parser = benepar.Parser(\"benepar_en3\")\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    pipeline\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package benepar_en3 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping models/benepar_en3.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dge0ghFNeSzK"
      },
      "source": [
        "본격적인 모델링에 앞서 실험 환경에서 GPU가 사용 가능한지 확인할 수 있습니다. `cuda`가 출력되면 GPU를 사용할 수 있는 것입니다. 단, GPU가 없다면 CPU를 사용해도 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn08se5feSzK",
        "outputId": "66ff1139-18ea-4a56-fe65-11c8ea3cc315"
      },
      "source": [
        "print('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8DreLbDeSzL"
      },
      "source": [
        "## 4.2 정답 단어 추출"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frCyxG4d1x5J"
      },
      "source": [
        "Wh- 문제를 생성하기 위한 첫 번째 단계는 지문에서 정답으로 사용할 단어를 추출하는 것입니다. 각 지문에서 `benepar_parser tree`를 통해 개체명을 인식하고 명사구에 해당하는 단어들만 추출하여 리스트로 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vpuanwQeSzL"
      },
      "source": [
        "def get_flattened(t):\n",
        "    sent_str_final = None\n",
        "    if t is not None:\n",
        "        sent_str = [\" \".join(x.leaves()) for x in list(t)]\n",
        "        sent_str_final = [\" \".join(sent_str)]\n",
        "        sent_str_final = sent_str_final[0]\n",
        "    return sent_str_final\n",
        "\n",
        "def get_NP(doc):\n",
        "    answers = []\n",
        "    trees = benepar_parser.parse_sents(sent_tokenize(doc))\n",
        "    for sent_idx, tree in enumerate(trees):\n",
        "        subtrees = tree.subtrees()\n",
        "        for subtree in subtrees:\n",
        "            if subtree.label() == \"NP\":\n",
        "                answers.append(get_flattened(subtree))\n",
        "    return answers    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmAnPoTeeSzL"
      },
      "source": [
        "## 4.3 문제 생성 클래스 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBDnKOXz3s3x"
      },
      "source": [
        "이번에는 Wh- 문제를 생성하는 클래스를 정의해보겠습니다. 위에서 추출한 정답 단어들과 지문을 T5기반의 Seq2SeqLM모델에 넣어 문제를 생성하게 됩니다. 여기서 사용된 토크나이저와 모델은 [huggingface](https://huggingface.co/models)가 제공하는 사전학습모델(API)을 가져와 사용하였습니다. 이 때, AutoModel API는 학습 가중치에 넣고자 하는 모델을 자동으로 찾아서 생성해주는 API입니다. 예를 들어 T5모델을 경로에 넣어주면 자동으로 T5구조를 생성해 그 안에 학습 가중치를 넣어주고, BERT모델을 경로에 넣어주면 BERT구조를 생성해 학습 가중치를 넣어주게 됩니다. 이번 QuestionGenerator 클래스에서는 [iarfmoose/t5-base-question-generator](https://huggingface.co/iarfmoose/t5-base-question-generator)를 불러왔습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDRg61x_eSzL"
      },
      "source": [
        "class QuestionGenerator():\n",
        "    def __init__(self):\n",
        "        QG_PRETRAINED = \"iarfmoose/t5-base-question-generator\"\n",
        "\n",
        "        self.ANSWER_TOKEN = \"<answer>\"\n",
        "        self.CONTEXT_TOKEN = \"<context>\"\n",
        "        self.SEQ_LENGTH = 512\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.qg_tokenizer = AutoTokenizer.from_pretrained(QG_PRETRAINED, use_fast=False)\n",
        "        self.qg_model = AutoModelForSeq2SeqLM.from_pretrained(QG_PRETRAINED)\n",
        "        self.qg_model.to(self.device)\n",
        "        self.qg_model.eval()\n",
        "\n",
        "    def generate_question(self, answers):\n",
        "        questions = []\n",
        "\n",
        "        for ans in answers: \n",
        "            qg_input = \"{} {} {} {}\".format(self.ANSWER_TOKEN, ans, self.CONTEXT_TOKEN, passage)\n",
        "            \n",
        "            encoded_input = self.qg_tokenizer(qg_input, padding='max_length', max_length=self.SEQ_LENGTH, truncation=True, return_tensors=\"pt\").to(self.device)\n",
        "            with torch.no_grad():\n",
        "                output = self.qg_model.generate(input_ids=encoded_input[\"input_ids\"])\n",
        "            question = self.qg_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "            questions.append(question)\n",
        "        return questions        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1MMwjdKeSzL"
      },
      "source": [
        "q_generator = QuestionGenerator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9_fvzaJeSzL"
      },
      "source": [
        "## 4.4 문제 평가 클래스 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3w3Z4sF8KGi"
      },
      "source": [
        "다음으로 생성된 문제와 정답쌍을 평가하는 클래스를 생성해보겠습니다. 문제와 정답간의 의미적 관련성을 Sequence Classification모델을 통해 점수매기게 됩니다. QAEvaluator 클래스에서는 [iarfmoose/bert-base-cased-qa-evaluator](https://huggingface.co/iarfmoose/bert-base-cased-qa-evaluator)를 사용하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl4kj4UFeSzM"
      },
      "source": [
        "class QAEvaluator():\n",
        "    def __init__(self):\n",
        "        QAE_PRETRAINED = \"iarfmoose/bert-base-cased-qa-evaluator\"\n",
        "        self.SEQ_LENGTH = 512\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.qae_tokenizer = AutoTokenizer.from_pretrained(QAE_PRETRAINED)\n",
        "        self.qae_model = AutoModelForSequenceClassification.from_pretrained(QAE_PRETRAINED)\n",
        "        self.qae_model.to(self.device)\n",
        "\n",
        "    def encode_qa_pairs(self, questions, answers):\n",
        "        encoded_pairs = []\n",
        "        for i in range(len(questions)):\n",
        "            encoded_qa = self.qae_tokenizer(text=questions[i], text_pair=answers[i], padding=\"max_length\", max_length=self.SEQ_LENGTH, truncation=True, return_tensors=\"pt\")\n",
        "            encoded_pairs.append(encoded_qa.to(self.device))\n",
        "        return encoded_pairs\n",
        "\n",
        "    def get_scores(self, encoded_qa_pairs):\n",
        "        scores = {}\n",
        "        self.qae_model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i in range(len(encoded_qa_pairs)):\n",
        "                scores[i] = self.qae_model(**encoded_qa_pairs[i])[0][0][1]\n",
        "        return [k for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8D0wbaKeSzM"
      },
      "source": [
        "qa_evaluator = QAEvaluator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8WBeEeqeSzM"
      },
      "source": [
        "## 4.5 오답 생성 클래스 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEwoKICH-O4z"
      },
      "source": [
        "마지막으로 오답을 생성하는 클래스를 정의해보겠습니다. 4.3절에서 추출한 정답 단어를 제외하고 4개의 보기 중 3개의 오답이 필요합니다. 이는 정답 단어에서 명사에 해당하는 첫 단어를 추출해 마스킹하고, BERT모델을 통해 그 부분을 다른 단어로 생성하게 됩니다. DistractorGenerator 클래스에서는 [bert-base-cased](https://huggingface.co/bert-base-cased)를 사용하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUMFiPideSzM"
      },
      "source": [
        "class DistractorGenerator():\n",
        "    def __init__(self):\n",
        "        self.unmasker = pipeline('fill-mask', model='bert-base-cased')  \n",
        "\n",
        "    def generate_distractor(self, text, candidate, answers, NNs: list):\n",
        "        distractor = []\n",
        "        divided = word_tokenize(text)\n",
        "        substitute_word = NNs[0]\n",
        "\n",
        "        mask_index = divided.index(substitute_word)\n",
        "        divided.pop(mask_index)\n",
        "\n",
        "        divided.insert(mask_index, '[MASK]')\n",
        "        text = ' '.join(divided)\n",
        "        unmasked_result = self.unmasker(text, top_k=10)[candidate]\n",
        "\n",
        "        text = unmasked_result[\"sequence\"]\n",
        "\n",
        "        answers = answers.split(' ')\n",
        "        answer_index = answers.index(substitute_word)\n",
        "        answers.pop(answer_index)\n",
        "        answers.insert(answer_index, unmasked_result[\"token_str\"])\n",
        "        return \" \".join(answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edqOakxkuFo5"
      },
      "source": [
        "def get_NN(distractor):\n",
        "      NNs = []\n",
        "      tree = benepar_parser.parse(distractor)\n",
        "      subtrees = tree.subtrees()\n",
        "      for subtree in subtrees:\n",
        "          if subtree.label() in [\"NN\", \"NNP\", \"NNS\", \"VB\"]: #VB for edge case\n",
        "              NNs.extend(subtree.leaves())       \n",
        "      return NNs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXsuNoqHsK6g"
      },
      "source": [
        "d_generator = DistractorGenerator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfw-NOLseSzN"
      },
      "source": [
        "## 4.6 Wh- 문제 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA2KTdLvAOnn"
      },
      "source": [
        "지금까지 정의한 클래스를 사용하여 지문에 대한 Wh- 문제를 생성해보겠습니다. 먼저 생성한 문제와 보기들을 저장할 데이터 프레임을 생성하고, 사용할 지문 20개를 선정합니다.(20개의 번호는 임의로 선정하였습니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iEjOXz1eSzN"
      },
      "source": [
        "df_WHQuestions = pd.DataFrame({'id': np.zeros(20),\n",
        "                               'passage': np.zeros(20),\n",
        "                               'question': np.zeros(20),\n",
        "                               'distractor_1': np.zeros(20),\n",
        "                               'distractor_2': np.zeros(20),\n",
        "                               'distractor_3': np.zeros(20),\n",
        "                               'distractor_4': np.zeros(20)})\n",
        "\n",
        "passage_id_list = [163, 28, 62, 57, 35, 26, 22, 151, 108, 55, 59, 129, 167, 143, 50, 161, 107, 56, 114, 71]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN6Din9vAr0Q"
      },
      "source": [
        "정의한 클래스들을 순서대로 진행합니다. 중간에 정답이 4단어를 넘지 않도록 제한하는 과정과 오답을 생성하기 전에 정답이 있는 문장을 찾아주는 과정이 포함되어 있습니다. 그리고 최종 생성한 문제, 정답, 오답은 데이터 프레임에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZmhawJHeSzN"
      },
      "source": [
        "df_idx = 0\n",
        "\n",
        "for passage_id in passage_id_list:\n",
        "\n",
        "    passage = data[passage_id]\n",
        "\n",
        "    answers = get_NP(passage)\n",
        "\n",
        "    questions = q_generator.generate_question(answers)\n",
        "\n",
        "    encoded_qa_pairs = qa_evaluator.encode_qa_pairs(questions, answers)\n",
        "    scores = qa_evaluator.get_scores(encoded_qa_pairs)\n",
        "    \n",
        "    ## 정답의 단어 개수 len() <= 4 사용한다. \n",
        "    for i in range(len(scores)):\n",
        "        index = scores[i]\n",
        "        if len(answers[index].split(' ')) > 4:\n",
        "            continue\n",
        "        break\n",
        "    \n",
        "    sentences = nltk.sent_tokenize(passage)\n",
        "    for sentence in sentences:\n",
        "        if answers[index] in sentence:\n",
        "            target_sentence = sentence\n",
        "\n",
        "    NNs = get_NN(answers[index])\n",
        "\n",
        "    distractors = []\n",
        "    for i in range(3):\n",
        "        distractors.append(d_generator.generate_distractor(target_sentence, 9-i, answers[index], NNs))\n",
        "    \n",
        "    df_WHQuestions.loc[df_idx] = [passage_id, passage, questions[index].split(\"?\")[0] + \"?\", answers[index]] + distractors\n",
        "    print(f\"finished {passage_id}\")\n",
        "    df_idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5enE5ipLCa4y"
      },
      "source": [
        "최종 생성된 결과는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_xjaBjZmm5GN",
        "outputId": "f8aeab55-5878-4612-a385-62226713a39f"
      },
      "source": [
        "df_WHQuestions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>passage</th>\n",
              "      <th>question</th>\n",
              "      <th>distractor_1</th>\n",
              "      <th>distractor_2</th>\n",
              "      <th>distractor_3</th>\n",
              "      <th>distractor_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>163.0</td>\n",
              "      <td>The waters of the culinary seas had been calm ...</td>\n",
              "      <td>What is the best definition of a mother who ca...</td>\n",
              "      <td>A mother who works</td>\n",
              "      <td>A cook who works</td>\n",
              "      <td>A kid who works</td>\n",
              "      <td>A waitress who works</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.0</td>\n",
              "      <td>The world is increasingly becoming flat with a...</td>\n",
              "      <td>What are the disadvantages of social network s...</td>\n",
              "      <td>The cyber communication</td>\n",
              "      <td>The cyber network</td>\n",
              "      <td>The cyber environment</td>\n",
              "      <td>The cyber community</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62.0</td>\n",
              "      <td>The best places for y...</td>\n",
              "      <td>What country is the best place to visit for yo...</td>\n",
              "      <td>a different country</td>\n",
              "      <td>a different village</td>\n",
              "      <td>a different generation</td>\n",
              "      <td>a different town</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57.0</td>\n",
              "      <td>Puerquitour: A great experience for your mouth...</td>\n",
              "      <td>Where did we go to watch the movie Renoir?</td>\n",
              "      <td>a movie theatre</td>\n",
              "      <td>a new theatre</td>\n",
              "      <td>a big theatre</td>\n",
              "      <td>a pizza theatre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.0</td>\n",
              "      <td>Nowadays, social media sites are commonly used...</td>\n",
              "      <td>What are the advantages of using social media ...</td>\n",
              "      <td>Substantial costs</td>\n",
              "      <td>Substantial parts</td>\n",
              "      <td>Substantial events</td>\n",
              "      <td>Substantial frames</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>26.0</td>\n",
              "      <td>Interpersonal skills, like any other skills re...</td>\n",
              "      <td>What are the two most popular social media app...</td>\n",
              "      <td>Skype and Facetime</td>\n",
              "      <td>Word and Facetime</td>\n",
              "      <td>Flash and Facetime</td>\n",
              "      <td>email and Facetime</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>22.0</td>\n",
              "      <td>Nowadays, with the advancement of technology, ...</td>\n",
              "      <td>What is the reason why a person may not have a...</td>\n",
              "      <td>anymore contact</td>\n",
              "      <td>anymore interactions</td>\n",
              "      <td>anymore dealings</td>\n",
              "      <td>anymore sex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>151.0</td>\n",
              "      <td>In this century there have been many technolog...</td>\n",
              "      <td>What is the most important aspect of television?</td>\n",
              "      <td>The entertainment aspect</td>\n",
              "      <td>The technical aspect</td>\n",
              "      <td>The broadcasting aspect</td>\n",
              "      <td>The political aspect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>108.0</td>\n",
              "      <td>I met a friend about one week ago, and he aske...</td>\n",
              "      <td>What is the feeling that you have now?</td>\n",
              "      <td>an awful feeling</td>\n",
              "      <td>an awful question</td>\n",
              "      <td>an awful think</td>\n",
              "      <td>an awful thinking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>55.0</td>\n",
              "      <td>Dear Sir or Madam,\\nI am writing to apply for ...</td>\n",
              "      <td>What do you hope to get from this job?</td>\n",
              "      <td>valuable experience</td>\n",
              "      <td>valuable ##s</td>\n",
              "      <td>valuable tips</td>\n",
              "      <td>valuable time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>59.0</td>\n",
              "      <td>Anna knew that it was going to be a very speci...</td>\n",
              "      <td>What was the day she was going to meet her mot...</td>\n",
              "      <td>a very special day</td>\n",
              "      <td>a very special experience</td>\n",
              "      <td>a very special week</td>\n",
              "      <td>a very special one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>129.0</td>\n",
              "      <td>On Britain's roads there is an ever-increasing...</td>\n",
              "      <td>What would be the easiest solution to this may...</td>\n",
              "      <td>an easy solution</td>\n",
              "      <td>an easy exit</td>\n",
              "      <td>an easy path</td>\n",
              "      <td>an easy reaction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>167.0</td>\n",
              "      <td>According the Lunde, 35% of homicide victims a...</td>\n",
              "      <td>How many statistics are greater than Lundes' t...</td>\n",
              "      <td>Statistics from 56</td>\n",
              "      <td>Appeals from 56</td>\n",
              "      <td>quotes from 56</td>\n",
              "      <td>gains from 56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>143.0</td>\n",
              "      <td>\"In Vitro fertilisation\" is the fertilisation ...</td>\n",
              "      <td>What is the definition of a woman who is given...</td>\n",
              "      <td>a post-menopausal woman</td>\n",
              "      <td>a post-menopausal man</td>\n",
              "      <td>a post-menopausal mother</td>\n",
              "      <td>a post-menopausal survivor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>50.0</td>\n",
              "      <td>Dear Mrs. Ashby, \\n\\nYesterday I was in Green ...</td>\n",
              "      <td>What kind of food do you like to serve?</td>\n",
              "      <td>Italian pasta</td>\n",
              "      <td>Italian sandwiches</td>\n",
              "      <td>Italian sauce</td>\n",
              "      <td>Italian restaurants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>161.0</td>\n",
              "      <td>Computers have definitely affected peoples liv...</td>\n",
              "      <td>What program does he use to make the calculati...</td>\n",
              "      <td>the Communications program</td>\n",
              "      <td>the Communications software</td>\n",
              "      <td>the Communications Unit</td>\n",
              "      <td>the Communications System</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>107.0</td>\n",
              "      <td>Cricket is my passion. I love playing, watchin...</td>\n",
              "      <td>What is the best way to learn more about cricket?</td>\n",
              "      <td>more about bowling</td>\n",
              "      <td>more about India</td>\n",
              "      <td>more about themselves</td>\n",
              "      <td>more about life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>56.0</td>\n",
              "      <td>Well, I would like to talk about my school lif...</td>\n",
              "      <td>What is the best place to study in the UK?</td>\n",
              "      <td>university</td>\n",
              "      <td>UCLA</td>\n",
              "      <td>USC</td>\n",
              "      <td>Purdue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>114.0</td>\n",
              "      <td>I have been learning English as a second langu...</td>\n",
              "      <td>How long ago did I decide to take the Cambridg...</td>\n",
              "      <td>One year</td>\n",
              "      <td>One hour</td>\n",
              "      <td>One decade</td>\n",
              "      <td>One weekend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>71.0</td>\n",
              "      <td>Glad to hear that you've been invited to att...</td>\n",
              "      <td>How long will you wait for a candidate who's l...</td>\n",
              "      <td>one more minute</td>\n",
              "      <td>one more person</td>\n",
              "      <td>one more night</td>\n",
              "      <td>one more opportunity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ...                distractor_4\n",
              "0   163.0  ...        A waitress who works\n",
              "1    28.0  ...         The cyber community\n",
              "2    62.0  ...            a different town\n",
              "3    57.0  ...             a pizza theatre\n",
              "4    35.0  ...          Substantial frames\n",
              "5    26.0  ...          email and Facetime\n",
              "6    22.0  ...                 anymore sex\n",
              "7   151.0  ...        The political aspect\n",
              "8   108.0  ...           an awful thinking\n",
              "9    55.0  ...               valuable time\n",
              "10   59.0  ...          a very special one\n",
              "11  129.0  ...            an easy reaction\n",
              "12  167.0  ...               gains from 56\n",
              "13  143.0  ...  a post-menopausal survivor\n",
              "14   50.0  ...         Italian restaurants\n",
              "15  161.0  ...   the Communications System\n",
              "16  107.0  ...             more about life\n",
              "17   56.0  ...                      Purdue\n",
              "18  114.0  ...                 One weekend\n",
              "19   71.0  ...        one more opportunity\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuE5c2iBDItE"
      },
      "source": [
        "생성된 문제와 보기를 보면 문법적으로는 어느 정도 잘 생성해내는 것 같습니다. 하지만 단순하게 명사를 추출하여 보기를 만들었기 때문에 지문에서 크게 중요하지 않은 질문들도 있고 엉뚱한 보기도 있어보입니다. 정답과 오답을 잘 고른다면 좀 더 유의미한 문제를 생성할 것이라고 기대되어집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrtKflVheSzQ"
      },
      "source": [
        "지금까지 Huggingface에서 제공하는 사전학습모델들로 Wh- 문제를 생성해보았습니다. 만약 SQuAD와 같은 QA 데이터셋이 있다면, 각자 생성하고 싶은 도메인으로 학습시켜 특화된 질문을 만드는데 활용해보시기 바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESE-Ym3XeSzQ"
      },
      "source": [
        "## 4.7 참고문헌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R00HWYzueSzR"
      },
      "source": [
        "- [Question_Generator](https://github.com/AMontgomerie/question_generator)\n",
        "- [huggingface](https://huggingface.co/models)\n"
      ]
    }
  ]
}